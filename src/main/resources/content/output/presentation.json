[{"SlideNum":1,"PageNum":1,"Title":"NBER WORKING PAPER SERIES","Paragraph":"***START OF PAGE 1***\nNBER WORKING PAPER SERIES\nTHE IMPACT OF ARTIFICIAL INTELLIGENCE ON INNOVATION\nIain M. Cockburn\nRebecca Henderson\nScott Stern\nWorking Paper 24449\nhttp://www.nber.org/papers/w24449\nNATIONAL BUREAU OF ECONOMIC RESEARCH\n1050 Massachusetts Avenue\nCambridge, MA 02138\nMarch 2018\nThe authors would like to thank the organizers and participants at the first NBER conference on\nthe Economics of Artificial Intelligence, and in particular our discussant Matthew Mitchell for\nmany helpful suggestions and ideas. Michael Kearney provided extraordinary research assistance.\nThe views expressed herein are those of the authors and do not necessarily reflect the views of the\nNational Bureau of Economic Research. Funding for this paper was provided by the MIT Sloan\nSchool of Management, by the HBS Division of Research and by the Questrom School of\nManagement.\nAt least one co-author has disclosed a financial relationship of potential relevance for this\nresearch. Further information is available online at http://www.nber.org/papers/w24449.ack\nNBER working papers are circulated for discussion and comment purposes. They have not been\npeer-reviewed or been subject to the review by the NBER Board of Directors that accompanies\nofficial NBER publications.\n© 2018 by Iain M. Cockburn, Rebecca Henderson, and Scott Stern. All rights reserved. Short\nsections of text, not to exceed two paragraphs, may be quoted without explicit permission\nprovided that full credit, including © notice, is given to the source.\n***END OF PAGE 1***","title":"NBER WORKING PAPER SERIES","slideNum":1,"paragraph":"***START OF PAGE 1***\nNBER WORKING PAPER SERIES\nTHE IMPACT OF ARTIFICIAL INTELLIGENCE ON INNOVATION\nIain M. Cockburn\nRebecca Henderson\nScott Stern\nWorking Paper 24449\nhttp://www.nber.org/papers/w24449\nNATIONAL BUREAU OF ECONOMIC RESEARCH\n1050 Massachusetts Avenue\nCambridge, MA 02138\nMarch 2018\nThe authors would like to thank the organizers and participants at the first NBER conference on\nthe Economics of Artificial Intelligence, and in particular our discussant Matthew Mitchell for\nmany helpful suggestions and ideas. Michael Kearney provided extraordinary research assistance.\nThe views expressed herein are those of the authors and do not necessarily reflect the views of the\nNational Bureau of Economic Research. Funding for this paper was provided by the MIT Sloan\nSchool of Management, by the HBS Division of Research and by the Questrom School of\nManagement.\nAt least one co-author has disclosed a financial relationship of potential relevance for this\nresearch. Further information is available online at http://www.nber.org/papers/w24449.ack\nNBER working papers are circulated for discussion and comment purposes. They have not been\npeer-reviewed or been subject to the review by the NBER Board of Directors that accompanies\nofficial NBER publications.\n© 2018 by Iain M. Cockburn, Rebecca Henderson, and Scott Stern. All rights reserved. Short\nsections of text, not to exceed two paragraphs, may be quoted without explicit permission\nprovided that full credit, including © notice, is given to the source.\n***END OF PAGE 1***","image":[],"pageNum":1},{"SlideNum":2,"PageNum":2,"Title":"The Impact of Artificial Intelligence on Innovation","Paragraph":"***START OF PAGE 2***\nThe Impact of Artificial Intelligence on Innovation\nIain M. Cockburn, Rebecca Henderson, and Scott Stern\nNBER Working Paper No. 24449\nMarch 2018\nJEL No. L1\nABSTRACT\nArtificial intelligence may greatly increase the efficiency of the existing economy. But it may\nhave an even larger impact by serving as a new general-purpose “method of invention” that can\nreshape the nature of the innovation process and the organization of R&D.  We distinguish\nbetween automation-oriented applications such as robotics and the potential for recent\ndevelopments in “deep learning” to serve as a general-purpose method of invention, finding\nstrong evidence of a “shift” in the importance of application-oriented learning research since\n2009. We suggest that this is likely to lead to a significant substitution away from more routinized\nlabor-intensive research towards research that takes advantage of the interplay between passively\ngenerated large datasets and enhanced prediction algorithms.  At the same time, the potential\ncommercial rewards from mastering this mode of research are likely to usher in a period of\nracing, driven by powerful incentives for individual companies to acquire and control critical\nlarge datasets and application-specific algorithms.  We suggest that policies which encourage\ntransparency and sharing of core datasets across both public and private actors may be critical\ntools for stimulating research productivity and innovation-oriented competition going forward.\nIain M. Cockburn\nSchool of Management\nBoston University\n595 Commonwealth Ave\nBoston, MA 02215\nand NBER\ncockburn@bu.edu\nRebecca Henderson\nHeinz Professor of Environmental Management\nHarvard Business School\nMorgan 445\nSoldiers Field\nBoston, MA 02163\nand NBER\nrhenderson@hbs.edu\nScott Stern\nMIT Sloan School of Management\n100 Main Street, E62-476\nCambridge, MA 02142\nand NBER\nsstern@mit.edu\n***END OF PAGE 2***","title":"The Impact of Artificial Intelligence on Innovation","slideNum":2,"paragraph":"***START OF PAGE 2***\nThe Impact of Artificial Intelligence on Innovation\nIain M. Cockburn, Rebecca Henderson, and Scott Stern\nNBER Working Paper No. 24449\nMarch 2018\nJEL No. L1\nABSTRACT\nArtificial intelligence may greatly increase the efficiency of the existing economy. But it may\nhave an even larger impact by serving as a new general-purpose “method of invention” that can\nreshape the nature of the innovation process and the organization of R&D.  We distinguish\nbetween automation-oriented applications such as robotics and the potential for recent\ndevelopments in “deep learning” to serve as a general-purpose method of invention, finding\nstrong evidence of a “shift” in the importance of application-oriented learning research since\n2009. We suggest that this is likely to lead to a significant substitution away from more routinized\nlabor-intensive research towards research that takes advantage of the interplay between passively\ngenerated large datasets and enhanced prediction algorithms.  At the same time, the potential\ncommercial rewards from mastering this mode of research are likely to usher in a period of\nracing, driven by powerful incentives for individual companies to acquire and control critical\nlarge datasets and application-specific algorithms.  We suggest that policies which encourage\ntransparency and sharing of core datasets across both public and private actors may be critical\ntools for stimulating research productivity and innovation-oriented competition going forward.\nIain M. Cockburn\nSchool of Management\nBoston University\n595 Commonwealth Ave\nBoston, MA 02215\nand NBER\ncockburn@bu.edu\nRebecca Henderson\nHeinz Professor of Environmental Management\nHarvard Business School\nMorgan 445\nSoldiers Field\nBoston, MA 02163\nand NBER\nrhenderson@hbs.edu\nScott Stern\nMIT Sloan School of Management\n100 Main Street, E62-476\nCambridge, MA 02142\nand NBER\nsstern@mit.edu\n***END OF PAGE 2***","image":[],"pageNum":2},{"SlideNum":3,"PageNum":3,"Title":"I Introduction","Paragraph":"***START OF PAGE 3***\nI. Introduction\nRapid advances in the field of artificial intelligence have profound implications for the\neconomy as well as society at large.  These innovations have the potential to directly influence\nboth the production and the characteristics of a wide range of products and services, with\nimportant implications for productivity, employment, and competition.  But, as important as\nthese effects are likely to be, artificial intelligence also has the potential to change the innovation\nprocess itself, with consequences that may be equally profound, and which may, over time, come\nto dominate the direct effect.\nConsider the case of Atomwise, a startup firm which is developing novel technology for\nidentifying potential drug candidates (and insecticides) by using neural networks to predict the\nbioactivity of candidate molecules.  The company reports that its deep convolutional neural\nnetworks “far surpass” the performance of conventional “docking” algorithms.  After appropriate\ntraining on vast quantities of data, the company’s AtomNet product is described as being able to\n“recognize” foundational building blocks of organic chemistry, and is capable of generating\nhighly accurate predictions of the outcomes of real-world physical experiments (Wallach et al.,\n2015).  Such breakthroughs hold out the prospect of substantial improvements in the productivity\nof early stage drug screening.  Of course, Atomwise’s technology (and that of other companies\nleveraging artificial intelligence to advance drug discovery or medical diagnosis) is still at an\nearly stage:  though their initial results seem to be promising, no new drugs have actually come\nto market using these new approaches.  But whether or not Atomwise delivers fully on its\npromise, its technology is representative of the ongoing attempt to develop a new innovation\n“playbook”, one that leverages large datasets and learning algorithms to engage in precise\nprediction of biological phenomena in order to guide design effective interventions. Atomwise,\nfor example, is now deploying this approach to the discovery and development of new pesticides\nand agents for controlling crop diseases.\nAtomwise’s example illustrates two of the ways in which advances in artificial intelligence\nhave the potential to impact innovation.  First, though the origins of artificial intelligence are\nbroadly in the field of computer science, and its early commercial applications have been in\nrelatively narrow domains such as robotics, the learning algorithms that are now being developed\n***END OF PAGE 3***","title":"I Introduction","slideNum":3,"paragraph":"***START OF PAGE 3***\nI. Introduction\nRapid advances in the field of artificial intelligence have profound implications for the\neconomy as well as society at large.  These innovations have the potential to directly influence\nboth the production and the characteristics of a wide range of products and services, with\nimportant implications for productivity, employment, and competition.  But, as important as\nthese effects are likely to be, artificial intelligence also has the potential to change the innovation\nprocess itself, with consequences that may be equally profound, and which may, over time, come\nto dominate the direct effect.\nConsider the case of Atomwise, a startup firm which is developing novel technology for\nidentifying potential drug candidates (and insecticides) by using neural networks to predict the\nbioactivity of candidate molecules.  The company reports that its deep convolutional neural\nnetworks “far surpass” the performance of conventional “docking” algorithms.  After appropriate\ntraining on vast quantities of data, the company’s AtomNet product is described as being able to\n“recognize” foundational building blocks of organic chemistry, and is capable of generating\nhighly accurate predictions of the outcomes of real-world physical experiments (Wallach et al.,\n2015).  Such breakthroughs hold out the prospect of substantial improvements in the productivity\nof early stage drug screening.  Of course, Atomwise’s technology (and that of other companies\nleveraging artificial intelligence to advance drug discovery or medical diagnosis) is still at an\nearly stage:  though their initial results seem to be promising, no new drugs have actually come\nto market using these new approaches.  But whether or not Atomwise delivers fully on its\npromise, its technology is representative of the ongoing attempt to develop a new innovation\n“playbook”, one that leverages large datasets and learning algorithms to engage in precise\nprediction of biological phenomena in order to guide design effective interventions. Atomwise,\nfor example, is now deploying this approach to the discovery and development of new pesticides\nand agents for controlling crop diseases.\nAtomwise’s example illustrates two of the ways in which advances in artificial intelligence\nhave the potential to impact innovation.  First, though the origins of artificial intelligence are\nbroadly in the field of computer science, and its early commercial applications have been in\nrelatively narrow domains such as robotics, the learning algorithms that are now being developed\n***END OF PAGE 3***","image":[],"pageNum":3},{"SlideNum":4,"PageNum":4,"Title":"suggest that artificial intelligence may ultimately have applications across a very wide range","Paragraph":"***START OF PAGE 4***\nsuggest that artificial intelligence may ultimately have applications across a very wide range.\nFrom the perspective of the economics of innovation (among others, Bresnahan and Trajtenberg\n(1995)), there is an important distinction between the problem of providing innovation incentives\nto develop technologies with a relatively narrow domain of application, such robots purpose-\nbuilt for narrow tasks, versus technologies with a wide—advocates might say almost limitless—\ndomain of application, as may be true of the advances in neural networks and machine learning\noften referred to as “deep learning.”  As such, a first question to be asked is the degree to which\ndevelopments in artificial intelligence are not simply examples of new technologies, but rather\nmay be the kinds of “general purpose technologies” (hereafter GPTs) that have historically been\nsuch influential drivers of long-term technological progress.\nSecond, while some applications of artificial intelligence will surely constitute lower-cost or\nhigher-quality inputs into many existing production processes (spurring concerns about the\npotential for large job displacements), others, such as deep learning, hold out the prospect of not\nonly productivity gains across a wide variety of sectors but also changes in the very nature of the\ninnovation process within those domains.  As articulated famously by Griliches (1957), by\nenabling innovation across many applications, the “invention of a method of invention” has the\npotential to have much larger economic impact than development of any single new product.\nHere we argue that recent advances in machine learning and neural networks, through their\nability to improve both the performance of end use technologies and the nature of the innovation\nprocess, are likely to have a particularly large impact on innovation and growth.  Thus the\nincentives and obstacles that may shape the development and diffusion of these technologies are\nan important topic for economic research, and building an understanding of the conditions under\nwhich different potential innovators are able to gain access to these tools and to use them in a\npro-competitive way is a central concern for policy.\nThis essay begins to unpack the potential impact of advances in artificial intelligence on\ninnovation, and to identify the role that policy and institutions might play in providing effective\nincentives for innovation, diffusion, and competition in this area.  We begin in Section II by\nhighlighting the distinctive economics of research tools, of which deep learning applied to R&D\nproblems is such an intriguing example.  We focus on the interplay between the degree of\ngenerality of application of a new research tool and the role of research tools not simply in\n***END OF PAGE 4***","title":"suggest that artificial intelligence may ultimately have applications across a very wide range","slideNum":4,"paragraph":"***START OF PAGE 4***\nsuggest that artificial intelligence may ultimately have applications across a very wide range.\nFrom the perspective of the economics of innovation (among others, Bresnahan and Trajtenberg\n(1995)), there is an important distinction between the problem of providing innovation incentives\nto develop technologies with a relatively narrow domain of application, such robots purpose-\nbuilt for narrow tasks, versus technologies with a wide—advocates might say almost limitless—\ndomain of application, as may be true of the advances in neural networks and machine learning\noften referred to as “deep learning.”  As such, a first question to be asked is the degree to which\ndevelopments in artificial intelligence are not simply examples of new technologies, but rather\nmay be the kinds of “general purpose technologies” (hereafter GPTs) that have historically been\nsuch influential drivers of long-term technological progress.\nSecond, while some applications of artificial intelligence will surely constitute lower-cost or\nhigher-quality inputs into many existing production processes (spurring concerns about the\npotential for large job displacements), others, such as deep learning, hold out the prospect of not\nonly productivity gains across a wide variety of sectors but also changes in the very nature of the\ninnovation process within those domains.  As articulated famously by Griliches (1957), by\nenabling innovation across many applications, the “invention of a method of invention” has the\npotential to have much larger economic impact than development of any single new product.\nHere we argue that recent advances in machine learning and neural networks, through their\nability to improve both the performance of end use technologies and the nature of the innovation\nprocess, are likely to have a particularly large impact on innovation and growth.  Thus the\nincentives and obstacles that may shape the development and diffusion of these technologies are\nan important topic for economic research, and building an understanding of the conditions under\nwhich different potential innovators are able to gain access to these tools and to use them in a\npro-competitive way is a central concern for policy.\nThis essay begins to unpack the potential impact of advances in artificial intelligence on\ninnovation, and to identify the role that policy and institutions might play in providing effective\nincentives for innovation, diffusion, and competition in this area.  We begin in Section II by\nhighlighting the distinctive economics of research tools, of which deep learning applied to R&D\nproblems is such an intriguing example.  We focus on the interplay between the degree of\ngenerality of application of a new research tool and the role of research tools not simply in\n***END OF PAGE 4***","image":[],"pageNum":4},{"SlideNum":5,"PageNum":5,"Title":"enhancing the efficiency of research activity but in creating a new playbook for innovation","Paragraph":"***START OF PAGE 5***\nenhancing the efficiency of research activity but in creating a new “playbook” for innovation\nitself.  We then turn in Section III to briefly contrasting three key technological trajectories\nwithin AI—robotics, symbolic systems, and deep learning.  We propose that these often\nconflated fields will likely play very different roles in the future of innovation and technical\nchange.  Work in symbolic systems appears to have stalled and is likely to have relatively little\nimpact going forwards. And while developments in robotics have the potential to further displace\nhuman labor in the production of many goods and services, innovation in robotics technologies\nper se has relatively low potential to change the nature of innovation itself.  By contrast, deep\nlearning seems to be an area of research that is highly general-purpose and that has the potential\nto change the innovation process itself.\nWe explore whether this might indeed be the case through an examination of some\nquantitative empirical evidence on the evolution of different areas artificial intelligence in terms\nof scientific and technical outputs of AI researchers as measured (imperfectly) by the publication\nof papers and patents from 1990 through 2015.  In particular, we develop what we believe is the\nfirst systematic database that captures the corpus of scientific paper and patenting activity in\nartificial intelligence, broadly defined, and divides these outputs into those associated with\nrobotics, symbolic systems, and deep learning.   Though preliminary in nature (and inherently\nimperfect given that key elements of research activity in artificial intelligence may not be\nobservable using these traditional innovation metrics), we find striking evidence for a rapid and\nmeaningful shift in the application orientation of learning-oriented publications, particularly after\n2009.  The timing of this shift is informative, since it accords with qualitative evidence about the\nsurprisingly strong performance of so-called “deep learning” multi-layered neural networks in a\nrange of tasks including computer vision and other prediction tasks.  Supplementary evidence\n(not reported here) based on the citation patterns to authors such as Geoffrey Hinton who are\nleading figures in deep learning suggests a striking acceleration of work in just the last few years\nthat builds on a small number of algorithmic breakthroughs related to multi-layered neural\nnetworks.\nThough not a central aspect of the analysis for this paper, we further find that, whereas\nresearch on learning-oriented algorithms has had a slow and steady upward swing outside of the\n***END OF PAGE 5***","title":"enhancing the efficiency of research activity but in creating a new playbook for innovation","slideNum":5,"paragraph":"***START OF PAGE 5***\nenhancing the efficiency of research activity but in creating a new “playbook” for innovation\nitself.  We then turn in Section III to briefly contrasting three key technological trajectories\nwithin AI—robotics, symbolic systems, and deep learning.  We propose that these often\nconflated fields will likely play very different roles in the future of innovation and technical\nchange.  Work in symbolic systems appears to have stalled and is likely to have relatively little\nimpact going forwards. And while developments in robotics have the potential to further displace\nhuman labor in the production of many goods and services, innovation in robotics technologies\nper se has relatively low potential to change the nature of innovation itself.  By contrast, deep\nlearning seems to be an area of research that is highly general-purpose and that has the potential\nto change the innovation process itself.\nWe explore whether this might indeed be the case through an examination of some\nquantitative empirical evidence on the evolution of different areas artificial intelligence in terms\nof scientific and technical outputs of AI researchers as measured (imperfectly) by the publication\nof papers and patents from 1990 through 2015.  In particular, we develop what we believe is the\nfirst systematic database that captures the corpus of scientific paper and patenting activity in\nartificial intelligence, broadly defined, and divides these outputs into those associated with\nrobotics, symbolic systems, and deep learning.   Though preliminary in nature (and inherently\nimperfect given that key elements of research activity in artificial intelligence may not be\nobservable using these traditional innovation metrics), we find striking evidence for a rapid and\nmeaningful shift in the application orientation of learning-oriented publications, particularly after\n2009.  The timing of this shift is informative, since it accords with qualitative evidence about the\nsurprisingly strong performance of so-called “deep learning” multi-layered neural networks in a\nrange of tasks including computer vision and other prediction tasks.  Supplementary evidence\n(not reported here) based on the citation patterns to authors such as Geoffrey Hinton who are\nleading figures in deep learning suggests a striking acceleration of work in just the last few years\nthat builds on a small number of algorithmic breakthroughs related to multi-layered neural\nnetworks.\nThough not a central aspect of the analysis for this paper, we further find that, whereas\nresearch on learning-oriented algorithms has had a slow and steady upward swing outside of the\n***END OF PAGE 5***","image":[],"pageNum":5},{"SlideNum":6,"PageNum":6,"Title":"United States US researchers have had a less sustained commitment to learningoriented","Paragraph":"***START OF PAGE 6***\nUnited States, US researchers have had a less sustained commitment to learning-oriented\nresearch prior to 2009, and have been in a “catch up” mode ever since.\nFinally, we begin to explore some of the organizational, institutional and policy\nconsequences of our analysis.  We see machine learning as the “invention of a method of\ninvention” whose application depends, in each case, on having access not just to the underlying\nalgorithms but also to large, granular datasets on physical and social behavior.  Developments in\nneural networks and machine learning thus raise the question of, even if the underlying scientific\napproaches (i.e., the basic multi-layered neural networks algorithms) are open, prospects for\ncontinued progress in this field—and commercial applications thereof—are likely to be\nsignificantly impacted by terms of access to complementary data.  Specifically, if there are\nincreasing returns to scale or scope in data acquisition (there is more learning to be had from the\n“larger” dataset), it is possible that early or aggressive entrants into a particular application area\nmay be able to create a substantial and long-lasting competitive advantage over potential rivals\nmerely through the control over data rather than through formal intellectual property or demand-\nside network effects.  Strong incentives to maintain data privately has the additional potential\ndownside that data is not being shared across researchers, thus reducing the ability of all\nresearchers to access an even larger set of data that would arise from public aggregation.  As the\ncompetitive advantage of incumbents is reinforced, the power of new entrants to drive\ntechnological change may be weakened.  Though this is an important possibility, it is also the\ncase that, at least so far, there seems to be a significant amount of entry and experimentation\nacross most key application sectors.\nII. The Economics of New Research Tools:  The Interplay between New Methods of\nInvention and the Generality of Innovation\nAt least since Arrow (1962) and Nelson (1959), economists have appreciated the\npotential for significant underinvestment in research, particularly basic research or domains of\ninvention with low appropriability for the inventor.  Considerable insight has been gained into\nthe conditions under which the incentives for innovation may be more or less distorted, both in\nterms of their overall level and in terms of the direction of that research.  As we consider the\npotential impact of advances in AI on innovation, two ideas from this literature seem particularly\n***END OF PAGE 6***","title":"United States US researchers have had a less sustained commitment to learningoriented","slideNum":6,"paragraph":"***START OF PAGE 6***\nUnited States, US researchers have had a less sustained commitment to learning-oriented\nresearch prior to 2009, and have been in a “catch up” mode ever since.\nFinally, we begin to explore some of the organizational, institutional and policy\nconsequences of our analysis.  We see machine learning as the “invention of a method of\ninvention” whose application depends, in each case, on having access not just to the underlying\nalgorithms but also to large, granular datasets on physical and social behavior.  Developments in\nneural networks and machine learning thus raise the question of, even if the underlying scientific\napproaches (i.e., the basic multi-layered neural networks algorithms) are open, prospects for\ncontinued progress in this field—and commercial applications thereof—are likely to be\nsignificantly impacted by terms of access to complementary data.  Specifically, if there are\nincreasing returns to scale or scope in data acquisition (there is more learning to be had from the\n“larger” dataset), it is possible that early or aggressive entrants into a particular application area\nmay be able to create a substantial and long-lasting competitive advantage over potential rivals\nmerely through the control over data rather than through formal intellectual property or demand-\nside network effects.  Strong incentives to maintain data privately has the additional potential\ndownside that data is not being shared across researchers, thus reducing the ability of all\nresearchers to access an even larger set of data that would arise from public aggregation.  As the\ncompetitive advantage of incumbents is reinforced, the power of new entrants to drive\ntechnological change may be weakened.  Though this is an important possibility, it is also the\ncase that, at least so far, there seems to be a significant amount of entry and experimentation\nacross most key application sectors.\nII. The Economics of New Research Tools:  The Interplay between New Methods of\nInvention and the Generality of Innovation\nAt least since Arrow (1962) and Nelson (1959), economists have appreciated the\npotential for significant underinvestment in research, particularly basic research or domains of\ninvention with low appropriability for the inventor.  Considerable insight has been gained into\nthe conditions under which the incentives for innovation may be more or less distorted, both in\nterms of their overall level and in terms of the direction of that research.  As we consider the\npotential impact of advances in AI on innovation, two ideas from this literature seem particularly\n***END OF PAGE 6***","image":[],"pageNum":6},{"SlideNum":7,"PageNum":7,"Title":"importantthe potential for contracting problems associated with the development of a new","Paragraph":"***START OF PAGE 7***\nimportant—the potential for contracting problems associated with the development of a new\nbroadly applicable research tool, and the potential for coordination problems arising from\nadoption and diffusion of a new “general purpose technology.”  In contrast to technological\nprogress in relatively narrow domains, such as traditional automation and industrial robots, we\nargue that those areas of artificial intelligence evolving most rapidly—such as deep learning—\nare likely to raise serious challenges in both dimensions.\nFirst, consider the challenge in providing appropriate innovation incentives when an\ninnovation has potential to drive technological and organizational change across a wide number\nof distinct applications.  Such “general purpose technologies” (David, 1990; Bresnahan and\nTrajtenberg, 1995) often take the form of core inventions that have the potential to significantly\nenhance productivity or quality across a wide number of fields or sectors.  David’s (1990)\nfoundational study of the electric motor showed that this invention brought about enormous\ntechnological and organizational change across sectors as diverse as manufacturing, agriculture,\nretail, and residential construction.  Such “GPTs” are usually understood to meet three criteria\nthat distinguish them from other innovations: they have pervasive application across many\nsectors; they spawn further innovation in application sectors, and they themselves are rapidly\nimproving.\nAs emphasized by Bresnahan and Trajtenberg (1995), the presence of a general-purpose\ntechnology gives rise to both vertical and horizontal externalities in the innovation process that\ncan lead not just to underinvestment but also to distortions in the direction of investment,\ndepending on the degree to which private and social returns diverge across different application\nsectors.  Most notably, if there are “innovation complementarities” between the general purpose\ntechnology and each of the application sectors, lack of incentives in one sector can create an\nindirect externality that results in a system-wide reduction in innovative investment itself.  While\nthe private incentives for innovative investment in each application sector depend on its the\nmarket structure and appropriability conditions, that sector’s innovation enhances innovation in\nthe GPT itself, which then induces subsequent demand (and further innovation) in other\ndownstream application sectors.  These gains can rarely be appropriated within the originating\nsector.  Lack of coordination between the GPT and application sectors, as well as across\napplication sectors, is therefore likely to significantly reduce investment in innovation.  Despite\n***END OF PAGE 7***","title":"importantthe potential for contracting problems associated with the development of a new","slideNum":7,"paragraph":"***START OF PAGE 7***\nimportant—the potential for contracting problems associated with the development of a new\nbroadly applicable research tool, and the potential for coordination problems arising from\nadoption and diffusion of a new “general purpose technology.”  In contrast to technological\nprogress in relatively narrow domains, such as traditional automation and industrial robots, we\nargue that those areas of artificial intelligence evolving most rapidly—such as deep learning—\nare likely to raise serious challenges in both dimensions.\nFirst, consider the challenge in providing appropriate innovation incentives when an\ninnovation has potential to drive technological and organizational change across a wide number\nof distinct applications.  Such “general purpose technologies” (David, 1990; Bresnahan and\nTrajtenberg, 1995) often take the form of core inventions that have the potential to significantly\nenhance productivity or quality across a wide number of fields or sectors.  David’s (1990)\nfoundational study of the electric motor showed that this invention brought about enormous\ntechnological and organizational change across sectors as diverse as manufacturing, agriculture,\nretail, and residential construction.  Such “GPTs” are usually understood to meet three criteria\nthat distinguish them from other innovations: they have pervasive application across many\nsectors; they spawn further innovation in application sectors, and they themselves are rapidly\nimproving.\nAs emphasized by Bresnahan and Trajtenberg (1995), the presence of a general-purpose\ntechnology gives rise to both vertical and horizontal externalities in the innovation process that\ncan lead not just to underinvestment but also to distortions in the direction of investment,\ndepending on the degree to which private and social returns diverge across different application\nsectors.  Most notably, if there are “innovation complementarities” between the general purpose\ntechnology and each of the application sectors, lack of incentives in one sector can create an\nindirect externality that results in a system-wide reduction in innovative investment itself.  While\nthe private incentives for innovative investment in each application sector depend on its the\nmarket structure and appropriability conditions, that sector’s innovation enhances innovation in\nthe GPT itself, which then induces subsequent demand (and further innovation) in other\ndownstream application sectors.  These gains can rarely be appropriated within the originating\nsector.  Lack of coordination between the GPT and application sectors, as well as across\napplication sectors, is therefore likely to significantly reduce investment in innovation.  Despite\n***END OF PAGE 7***","image":[],"pageNum":7},{"SlideNum":8,"PageNum":8,"Title":"these challenges a reinforcing cycle of innovation between the GPT and a myriad of application","Paragraph":"***START OF PAGE 8***\nthese challenges, a reinforcing cycle of innovation between the GPT and a myriad of application\nsectors can generate a more systemic economy-wide transformation as the rate of innovation\nincreases across all sectors.  A rich empirical literature examining the productivity impacts of\ninformation technology point to the role of the microprocessor as a GPT as a way of\nunderstanding the impact of IT on the economy as a whole (among many others, Bresnahan and\nGreenstein (1995); Brynjolfsson and Hitt (1999); and Bresnahan, Brynjolfsson, and Hitt (2001)).\nVarious aspects of artificial intelligence can certainly be understood as a GPT, and learning from\nexamples such as the microprocessor are likely to be a useful foundation for thinking about both\nthe magnitude of their impact on the economy, and associated policy challenges.\nA second conceptual framework for thinking about AI is the economics of research tools.\nWithin the research sectors, some innovations open up new avenues of inquiry, or simply\nimprove productivity “within the lab”.  Some of these advances appear to have great potential\nacross a broad set of domains, beyond their initial application: as highlighted by Griliches (1957)\nin his classic studies of hybrid corn, some new research tools are inventions that do not just\ncreate or improve a specific product—instead they constitute a new way of creating new\nproducts, with much broader application.  In Griliches’ famous construction, the discovery of\ndouble-cross hybridization “was the invention of a method of inventing.”  (Hereinafter, “IMI”.)\nRather than being a means of creating a single a new corn variety, hybrid corn represented a\nwidely applicable method for breeding many different new varieties.  When applied to the\nchallenge of creating new varieties optimized for many different localities (and even more\nbroadly, to other crops) the invention of double-cross hybridization had a huge impact on\nagricultural productivity.\nOne of the important insights to be gained from thinking about IMIs, therefore, is that the\neconomic impact of some types of research tools is not limited to their ability to reduce the costs\nof specific innovation activities—perhaps even more consequentially they enable a new\napproach to innovation itself, by altering the “playbook” for innovation in the domains where the\nnew tool is applied.  For example, prior to the systematic understanding of the power of “hybrid\nvigor,” a primary focus in agriculture had been improved techniques for self-fertilization (i.e.,\nallowing for more and more specialized natural varietals over time).  Once the rules governing\nhybridization (i.e., heterosis) were systematized, and the performance advantages of hybrid vigor\n***END OF PAGE 8***","title":"these challenges a reinforcing cycle of innovation between the GPT and a myriad of application","slideNum":8,"paragraph":"***START OF PAGE 8***\nthese challenges, a reinforcing cycle of innovation between the GPT and a myriad of application\nsectors can generate a more systemic economy-wide transformation as the rate of innovation\nincreases across all sectors.  A rich empirical literature examining the productivity impacts of\ninformation technology point to the role of the microprocessor as a GPT as a way of\nunderstanding the impact of IT on the economy as a whole (among many others, Bresnahan and\nGreenstein (1995); Brynjolfsson and Hitt (1999); and Bresnahan, Brynjolfsson, and Hitt (2001)).\nVarious aspects of artificial intelligence can certainly be understood as a GPT, and learning from\nexamples such as the microprocessor are likely to be a useful foundation for thinking about both\nthe magnitude of their impact on the economy, and associated policy challenges.\nA second conceptual framework for thinking about AI is the economics of research tools.\nWithin the research sectors, some innovations open up new avenues of inquiry, or simply\nimprove productivity “within the lab”.  Some of these advances appear to have great potential\nacross a broad set of domains, beyond their initial application: as highlighted by Griliches (1957)\nin his classic studies of hybrid corn, some new research tools are inventions that do not just\ncreate or improve a specific product—instead they constitute a new way of creating new\nproducts, with much broader application.  In Griliches’ famous construction, the discovery of\ndouble-cross hybridization “was the invention of a method of inventing.”  (Hereinafter, “IMI”.)\nRather than being a means of creating a single a new corn variety, hybrid corn represented a\nwidely applicable method for breeding many different new varieties.  When applied to the\nchallenge of creating new varieties optimized for many different localities (and even more\nbroadly, to other crops) the invention of double-cross hybridization had a huge impact on\nagricultural productivity.\nOne of the important insights to be gained from thinking about IMIs, therefore, is that the\neconomic impact of some types of research tools is not limited to their ability to reduce the costs\nof specific innovation activities—perhaps even more consequentially they enable a new\napproach to innovation itself, by altering the “playbook” for innovation in the domains where the\nnew tool is applied.  For example, prior to the systematic understanding of the power of “hybrid\nvigor,” a primary focus in agriculture had been improved techniques for self-fertilization (i.e.,\nallowing for more and more specialized natural varietals over time).  Once the rules governing\nhybridization (i.e., heterosis) were systematized, and the performance advantages of hybrid vigor\n***END OF PAGE 8***","image":[],"pageNum":8},{"SlideNum":9,"PageNum":9,"Title":"demonstrated the techniques and conceptual approach for agricultural innovation was shifted","Paragraph":"***START OF PAGE 9***\ndemonstrated, the techniques and conceptual approach for agricultural innovation was shifted,\nushering in a long period of systematic innovation using these new tools and knowledge.\nAdvances in machine learning and neural networks appear to have great potential as a\nresearch tool in problems of classification and prediction.  These are both important limiting\nfactors in a variety of research tasks, and, as exemplified by the Atomwise example, application\nof “learning” approaches to AI hold out the prospect of dramatically lower costs and improved\nperformance in R&D projects where these are significant challenges.  But as with hybrid corn,\nAI based learning may be more usefully understood as an IMI than as a narrowly limited solution\nto a specific problem.  One the one hand, AI based learning may be able to substantially\n“automate discovery” across many domains where classification and prediction tasks play an\nimportant role.  On the other, they may also “expand the playbook” is the sense of opening up\nthe set of problems that can be feasibly addressed, and radically altering  scientific and technical\ncommunities’ conceptual approaches and framing of problems.  The invention of optical lenses\nin the 17th century had important direct economic impact in applications such as spectacles.  But\noptical lenses in the form of microscopes and telescopes also had enormous and long-lasting\nindirect effects on the progress of science, technological change, growth, and welfare: by making\nvery small or very distant objects visible for the first time, lenses opened up entirely new\ndomains of inquiry and technological opportunity.  Leung et al. (2016), for example, evocatively\ncharacterize machine learning as an opportunity to “learn to read the genome” in ways that\nhuman cognition and perception cannot.\nOf course, many research tools are neither IMIs nor GPTs, and their primary impact is to\nreduce the cost or enhance the quality of an existing innovation process.  For example, in the\npharmaceutical industry, new kinds of materials promise to enhance the efficiency of specific\nresearch processes.  Other research tools can indeed be thought of as IMIs but are nonetheless\nrelatively limited in application.  For example, the development of genetically engineered\nresearch mice (such as the Oncomouse) is an IMI that has had a profound impact on the conduct\nand “playbook” of biomedical research, but has no obvious relevance to innovation in areas such\nas information technology, energy, or aerospace.  The challenge presented by advances in AI is\nthat they appear to be research tools that not only have the potential to change the method of\ninnovation itself but also have implications across an extraordinarily wide range of fields.\n***END OF PAGE 9***","title":"demonstrated the techniques and conceptual approach for agricultural innovation was shifted","slideNum":9,"paragraph":"***START OF PAGE 9***\ndemonstrated, the techniques and conceptual approach for agricultural innovation was shifted,\nushering in a long period of systematic innovation using these new tools and knowledge.\nAdvances in machine learning and neural networks appear to have great potential as a\nresearch tool in problems of classification and prediction.  These are both important limiting\nfactors in a variety of research tasks, and, as exemplified by the Atomwise example, application\nof “learning” approaches to AI hold out the prospect of dramatically lower costs and improved\nperformance in R&D projects where these are significant challenges.  But as with hybrid corn,\nAI based learning may be more usefully understood as an IMI than as a narrowly limited solution\nto a specific problem.  One the one hand, AI based learning may be able to substantially\n“automate discovery” across many domains where classification and prediction tasks play an\nimportant role.  On the other, they may also “expand the playbook” is the sense of opening up\nthe set of problems that can be feasibly addressed, and radically altering  scientific and technical\ncommunities’ conceptual approaches and framing of problems.  The invention of optical lenses\nin the 17th century had important direct economic impact in applications such as spectacles.  But\noptical lenses in the form of microscopes and telescopes also had enormous and long-lasting\nindirect effects on the progress of science, technological change, growth, and welfare: by making\nvery small or very distant objects visible for the first time, lenses opened up entirely new\ndomains of inquiry and technological opportunity.  Leung et al. (2016), for example, evocatively\ncharacterize machine learning as an opportunity to “learn to read the genome” in ways that\nhuman cognition and perception cannot.\nOf course, many research tools are neither IMIs nor GPTs, and their primary impact is to\nreduce the cost or enhance the quality of an existing innovation process.  For example, in the\npharmaceutical industry, new kinds of materials promise to enhance the efficiency of specific\nresearch processes.  Other research tools can indeed be thought of as IMIs but are nonetheless\nrelatively limited in application.  For example, the development of genetically engineered\nresearch mice (such as the Oncomouse) is an IMI that has had a profound impact on the conduct\nand “playbook” of biomedical research, but has no obvious relevance to innovation in areas such\nas information technology, energy, or aerospace.  The challenge presented by advances in AI is\nthat they appear to be research tools that not only have the potential to change the method of\ninnovation itself but also have implications across an extraordinarily wide range of fields.\n***END OF PAGE 9***","image":[],"pageNum":9},{"SlideNum":10,"PageNum":10,"Title":"Historically technologies with these characteristicsthink of digital computinghave had large","Paragraph":"***START OF PAGE 10***\nHistorically technologies with these characteristics—think of digital computing—have had large\nand unanticipated impacts across the economy and society in general.  Mokyr (2002) points to\nthe profound impact of IMIs that take the form not of tools per se, but innovations in the way\nresearch is organized and conducted, such as the invention of the university.  GPTs that are\nthemselves IMIs (or vice versa) are particularly complex phenomena, whose dynamics are as yet\npoorly understood or characterized.\nFrom a policy perspective, a further important feature of research tools is that it may be\nparticularly difficult to appropriate their benefits. As emphasized by Scotchmer (1990),\nproviding appropriate incentives for an upstream innovator that develops only the first “stage” of\nan innovation (such as a research tool) can be particularly problematic when contracting is\nimperfect and the ultimate application of the new products whose development is enabled by the\nupstream innovation is uncertain.  Scotchmer and her co-authors emphasized a key point about a\nmulti-stage research process:  when the ultimate innovation that creates value requires multiple\nsteps, providing appropriate innovation incentives are not only a question of whether and how to\nprovide property rights in general, but also of how best to distribute property rights and\nincentives across the multiple stages of the innovation process.  Lack of incentives for early-\nstage innovation can therefore mean that the tools required for subsequent innovation do not\neven get invented; strong early-stage property rights without adequate contracting opportunities\nmay result in “hold-up” for later-stage innovators and so reduce the ultimate impact of the tool in\nterms of commercial application.\nThe vertical research spillovers created by new research tools (or IMIs) are not just a\nchallenge for designing appropriate intellectual property policy.1  They are also exemplars of the\ncore innovation externality highlighted by endogenous growth theory (Romer, 1990; Aghion and\nHowitt, 1992); a central source of underinvestment in innovation is the fact that the intertemporal\nspillovers from innovators today to innovators tomorrow cannot be easily captured.  While\ntomorrow’s innovators benefit from “standing on the shoulders of giants,” their gains are not\neasily shared with their predecessors.  This is not simply a theoretical idea: an increasing body of\nevidence suggests that research tools and the institutions that support their development and\n1 Challenges presented by AI-enabled invention for legal doctrine and the patent process are beyond the scope of\nthis essay.\n***END OF PAGE 10***","title":"Historically technologies with these characteristicsthink of digital computinghave had large","slideNum":10,"paragraph":"***START OF PAGE 10***\nHistorically technologies with these characteristics—think of digital computing—have had large\nand unanticipated impacts across the economy and society in general.  Mokyr (2002) points to\nthe profound impact of IMIs that take the form not of tools per se, but innovations in the way\nresearch is organized and conducted, such as the invention of the university.  GPTs that are\nthemselves IMIs (or vice versa) are particularly complex phenomena, whose dynamics are as yet\npoorly understood or characterized.\nFrom a policy perspective, a further important feature of research tools is that it may be\nparticularly difficult to appropriate their benefits. As emphasized by Scotchmer (1990),\nproviding appropriate incentives for an upstream innovator that develops only the first “stage” of\nan innovation (such as a research tool) can be particularly problematic when contracting is\nimperfect and the ultimate application of the new products whose development is enabled by the\nupstream innovation is uncertain.  Scotchmer and her co-authors emphasized a key point about a\nmulti-stage research process:  when the ultimate innovation that creates value requires multiple\nsteps, providing appropriate innovation incentives are not only a question of whether and how to\nprovide property rights in general, but also of how best to distribute property rights and\nincentives across the multiple stages of the innovation process.  Lack of incentives for early-\nstage innovation can therefore mean that the tools required for subsequent innovation do not\neven get invented; strong early-stage property rights without adequate contracting opportunities\nmay result in “hold-up” for later-stage innovators and so reduce the ultimate impact of the tool in\nterms of commercial application.\nThe vertical research spillovers created by new research tools (or IMIs) are not just a\nchallenge for designing appropriate intellectual property policy.1  They are also exemplars of the\ncore innovation externality highlighted by endogenous growth theory (Romer, 1990; Aghion and\nHowitt, 1992); a central source of underinvestment in innovation is the fact that the intertemporal\nspillovers from innovators today to innovators tomorrow cannot be easily captured.  While\ntomorrow’s innovators benefit from “standing on the shoulders of giants,” their gains are not\neasily shared with their predecessors.  This is not simply a theoretical idea: an increasing body of\nevidence suggests that research tools and the institutions that support their development and\n1 Challenges presented by AI-enabled invention for legal doctrine and the patent process are beyond the scope of\nthis essay.\n***END OF PAGE 10***","image":[],"pageNum":10},{"SlideNum":11,"PageNum":11,"Title":"diffusion play an important role in generating intertemporal spillovers among others Furman","Paragraph":"***START OF PAGE 11***\ndiffusion play an important role in generating intertemporal spillovers (among others, Furman\nand Stern, 2011; Williams, 2014).  A central insight of this work is that control—both in the\nform of physical exclusivity as well as in the form of formal intellectual property rights—over\ntools and data can shape both the level and direction of innovative activity, and that rules and\ninstitutions governing control over these areas has a powerful influence on the realized amount\nand nature of innovation.\nOf course, these frameworks cover only a subset of the key informational and\ncompetitive distortions that might arise when considering whether and how to provide optimal\nincentives for the type of technological change represented by some areas of AI.  But these two\nareas in particular seem likely to be important for understanding the implications of the current\ndramatic advances in AI supported learning. We therefore turn in the next section to a brief\noutline of the ways in which AI is changing, with an eye towards bringing the framework here to\nbear on how we might outline a research agenda exploring the innovation policy challenges that\nthey create.\nIII. The Evolution of Artificial Intelligence:  Robotics, Symbolic Systems, and Neural\nNetworks\nIn his omnibus historical account of AI research, Nilsson (2010) defines AI as “that\nactivity devoted to making machines intelligent, and intelligence is that quality that enables an\nentity to function appropriately and with foresight in its environment.” His account details the\ncontributions of multiple fields to achievements in AI, including but not limited to biology,\nlinguistics, psychology and cognitive sciences, neuroscience, mathematics, philosophy and logic,\nengineering and computer science.  And, of course, regardless of their particular approach,\nartificial intelligence research has been united by from the beginning by its engagement with\nTuring (1950), and his discussion of the possibility of mechanizing intelligence.\nThough often grouped together, the intellectual history of AI as a scientific and technical\nfield is usefully informed by distinguishing between three interrelated but separate areas:\nrobotics, neural networks, and symbolic systems.  Perhaps the most successful line of research in\nthe early years of AI—dating back to the 1960s—falls under the broad heading of symbolic\n***END OF PAGE 11***","title":"diffusion play an important role in generating intertemporal spillovers among others Furman","slideNum":11,"paragraph":"***START OF PAGE 11***\ndiffusion play an important role in generating intertemporal spillovers (among others, Furman\nand Stern, 2011; Williams, 2014).  A central insight of this work is that control—both in the\nform of physical exclusivity as well as in the form of formal intellectual property rights—over\ntools and data can shape both the level and direction of innovative activity, and that rules and\ninstitutions governing control over these areas has a powerful influence on the realized amount\nand nature of innovation.\nOf course, these frameworks cover only a subset of the key informational and\ncompetitive distortions that might arise when considering whether and how to provide optimal\nincentives for the type of technological change represented by some areas of AI.  But these two\nareas in particular seem likely to be important for understanding the implications of the current\ndramatic advances in AI supported learning. We therefore turn in the next section to a brief\noutline of the ways in which AI is changing, with an eye towards bringing the framework here to\nbear on how we might outline a research agenda exploring the innovation policy challenges that\nthey create.\nIII. The Evolution of Artificial Intelligence:  Robotics, Symbolic Systems, and Neural\nNetworks\nIn his omnibus historical account of AI research, Nilsson (2010) defines AI as “that\nactivity devoted to making machines intelligent, and intelligence is that quality that enables an\nentity to function appropriately and with foresight in its environment.” His account details the\ncontributions of multiple fields to achievements in AI, including but not limited to biology,\nlinguistics, psychology and cognitive sciences, neuroscience, mathematics, philosophy and logic,\nengineering and computer science.  And, of course, regardless of their particular approach,\nartificial intelligence research has been united by from the beginning by its engagement with\nTuring (1950), and his discussion of the possibility of mechanizing intelligence.\nThough often grouped together, the intellectual history of AI as a scientific and technical\nfield is usefully informed by distinguishing between three interrelated but separate areas:\nrobotics, neural networks, and symbolic systems.  Perhaps the most successful line of research in\nthe early years of AI—dating back to the 1960s—falls under the broad heading of symbolic\n***END OF PAGE 11***","image":[],"pageNum":11},{"SlideNum":12,"PageNum":12,"Title":"systems  Although early pioneers such as Turing had emphasized the importance of teaching a","Paragraph":"***START OF PAGE 12***\nsystems.  Although early pioneers such as Turing had emphasized the importance of teaching a\nmachine as one might a child (i.e., emphasizing AI as a learning process), the “symbol\nprocessing hypothesis” (Newell, Shaw, and Simon, 1958; Newell and Simon, 1976) was\npremised on the attempt to replicate the logical flow of human decision making through\nprocessing symbols.  Early attempts to instantiate this approach yielded striking success in\ndemonstration projects, such as the ability of a computer to navigate elements of a chess game\n(or other board games) or engage in relatively simple conversations with humans by following\nspecific heuristics and rules embedded into a program.  However, while research based on the\nconcept of a “general problem solver” has continued to be an area of significant academic\ninterest, and there have been periodic explosions of interest in the use of such approaches to\nassist human decision-making (e.g., in the context of early-stage expert systems to guide medical\ndiagnosis), the symbolic systems approach has been heavily criticized for its inability to\nmeaningfully impact real-world processes in a scalable way.  It is of course possible that this\nfield will see breakthroughs in the future, but it is fair to say that, while symbolic systems\ncontinues to be an area of academic research, it has not been central to the commercial\napplication of AI.  Nor is it at the heart of the recent reported advances in AI that are associated\nwith the area of machine learning and prediction.\nA second influential trajectory in AI has been broadly in the area of robotics.  While the\nconcepts of “robots” as machines that can perform human tasks dates back at least to the 1940s,\nthe field of robotics began to meaningfully flourish from the 1980s onwards through a\ncombination of the advances in numerically controlled machine tools and the development of\nmore adaptive but still rules-based robotics that rely on the active sensing of a known\nenvironment.  Perhaps the most economically consequential application of AI to date has been in\nthis area, with large scale deployment of “industrial robots” in manufacturing applications.\nThese machines are precisely programmed to undertake a given task in a highly controlled\nenvironment.  Often located in “cages” within highly specialized industrial processes (most\nnotably automobile manufacturing), these purpose-built tools are perhaps more aptly described\nas highly sophisticated numerically controlled machines rather than as robots with significant AI\ncontent.  Over the past twenty years, innovation in robotics has had an important impact on\nmanufacturing and automation, most notably through the introduction of more responsive robots\nthat rely on programmed response algorithms that can respond to a variety of stimuli.  This\n***END OF PAGE 12***","title":"systems  Although early pioneers such as Turing had emphasized the importance of teaching a","slideNum":12,"paragraph":"***START OF PAGE 12***\nsystems.  Although early pioneers such as Turing had emphasized the importance of teaching a\nmachine as one might a child (i.e., emphasizing AI as a learning process), the “symbol\nprocessing hypothesis” (Newell, Shaw, and Simon, 1958; Newell and Simon, 1976) was\npremised on the attempt to replicate the logical flow of human decision making through\nprocessing symbols.  Early attempts to instantiate this approach yielded striking success in\ndemonstration projects, such as the ability of a computer to navigate elements of a chess game\n(or other board games) or engage in relatively simple conversations with humans by following\nspecific heuristics and rules embedded into a program.  However, while research based on the\nconcept of a “general problem solver” has continued to be an area of significant academic\ninterest, and there have been periodic explosions of interest in the use of such approaches to\nassist human decision-making (e.g., in the context of early-stage expert systems to guide medical\ndiagnosis), the symbolic systems approach has been heavily criticized for its inability to\nmeaningfully impact real-world processes in a scalable way.  It is of course possible that this\nfield will see breakthroughs in the future, but it is fair to say that, while symbolic systems\ncontinues to be an area of academic research, it has not been central to the commercial\napplication of AI.  Nor is it at the heart of the recent reported advances in AI that are associated\nwith the area of machine learning and prediction.\nA second influential trajectory in AI has been broadly in the area of robotics.  While the\nconcepts of “robots” as machines that can perform human tasks dates back at least to the 1940s,\nthe field of robotics began to meaningfully flourish from the 1980s onwards through a\ncombination of the advances in numerically controlled machine tools and the development of\nmore adaptive but still rules-based robotics that rely on the active sensing of a known\nenvironment.  Perhaps the most economically consequential application of AI to date has been in\nthis area, with large scale deployment of “industrial robots” in manufacturing applications.\nThese machines are precisely programmed to undertake a given task in a highly controlled\nenvironment.  Often located in “cages” within highly specialized industrial processes (most\nnotably automobile manufacturing), these purpose-built tools are perhaps more aptly described\nas highly sophisticated numerically controlled machines rather than as robots with significant AI\ncontent.  Over the past twenty years, innovation in robotics has had an important impact on\nmanufacturing and automation, most notably through the introduction of more responsive robots\nthat rely on programmed response algorithms that can respond to a variety of stimuli.  This\n***END OF PAGE 12***","image":[],"pageNum":12},{"SlideNum":13,"PageNum":13,"Title":"approach famously pioneered by Rod Brooks  focused the commercial and innovation","Paragraph":"***START OF PAGE 13***\napproach, famously pioneered by Rod Brooks (1990), focused the commercial and innovation\norientation of AI away from the modeling of human-like intelligence towards providing feedback\nmechanisms that would allow for practical and effective robotics for specified applications.  This\ninsight led, among other applications, to the Roomba and to other adaptable industrial robots that\ncould interact with humans such as Rethink Robotics’ Baxter).  Continued innovation in robotics\ntechnologies (particularly in the ability of robotic devices to sense and interact with their\nenvironment) may lead to wider application and adoption outside industrial automation.\nThese advances are important, and the most advanced robots continue to capture public\nimagination when the term AI is invoked.  But innovations in robotics are not, generally\nspeaking, IMIs.  The increasing automation of laboratory equipment certainly improves research\nproductivity, but advances in robotics are not (yet) centrally connected to the underlying ways in\nwhich researchers themselves might develop approaches to undertake innovation itself across\nmultiple domains.  There are of course counterexamples to this proposition:  robotic space\nprobes have been a very important research tool in planetary science, and the ability of\nautomated remote sensing devices to collect data at very large scale or in challenging\nenvironments may transform some fields of research.  But robots continue to be used principally\nin specialized end-use “production” applications.\nFinally, a third stream of research that has been a central element of AI since its founding\ncan be broadly characterized as a “learning” approach.  Rather than being focused on symbolic\nlogic, or precise sense-and-react systems, the learning approach attempts to create reliable and\naccurate methods for the prediction of particular events (either physical or logical) in the\npresence of particular inputs.   The concept of a neural network has been particularly important\nin this area.   A neural network is a program that uses a combination of weights and thresholds to\ntranslate a set of inputs into a set of outputs, measures the “closeness” of these outputs to reality,\nand then adjusts the weights it uses to narrow the distance between outputs and reality. In this\nway, neural networks can learn as they are fed more inputs (Rosenblatt, 1958; 1963).  Over the\ncourse of the 1980s, Hinton and his co-authors further advanced the conceptual framework on\nwhich neural networks are based through the development of “back-propagating multi-layer”\ntechniques that further enhance their potential for supervised learning.\n***END OF PAGE 13***","title":"approach famously pioneered by Rod Brooks  focused the commercial and innovation","slideNum":13,"paragraph":"***START OF PAGE 13***\napproach, famously pioneered by Rod Brooks (1990), focused the commercial and innovation\norientation of AI away from the modeling of human-like intelligence towards providing feedback\nmechanisms that would allow for practical and effective robotics for specified applications.  This\ninsight led, among other applications, to the Roomba and to other adaptable industrial robots that\ncould interact with humans such as Rethink Robotics’ Baxter).  Continued innovation in robotics\ntechnologies (particularly in the ability of robotic devices to sense and interact with their\nenvironment) may lead to wider application and adoption outside industrial automation.\nThese advances are important, and the most advanced robots continue to capture public\nimagination when the term AI is invoked.  But innovations in robotics are not, generally\nspeaking, IMIs.  The increasing automation of laboratory equipment certainly improves research\nproductivity, but advances in robotics are not (yet) centrally connected to the underlying ways in\nwhich researchers themselves might develop approaches to undertake innovation itself across\nmultiple domains.  There are of course counterexamples to this proposition:  robotic space\nprobes have been a very important research tool in planetary science, and the ability of\nautomated remote sensing devices to collect data at very large scale or in challenging\nenvironments may transform some fields of research.  But robots continue to be used principally\nin specialized end-use “production” applications.\nFinally, a third stream of research that has been a central element of AI since its founding\ncan be broadly characterized as a “learning” approach.  Rather than being focused on symbolic\nlogic, or precise sense-and-react systems, the learning approach attempts to create reliable and\naccurate methods for the prediction of particular events (either physical or logical) in the\npresence of particular inputs.   The concept of a neural network has been particularly important\nin this area.   A neural network is a program that uses a combination of weights and thresholds to\ntranslate a set of inputs into a set of outputs, measures the “closeness” of these outputs to reality,\nand then adjusts the weights it uses to narrow the distance between outputs and reality. In this\nway, neural networks can learn as they are fed more inputs (Rosenblatt, 1958; 1963).  Over the\ncourse of the 1980s, Hinton and his co-authors further advanced the conceptual framework on\nwhich neural networks are based through the development of “back-propagating multi-layer”\ntechniques that further enhance their potential for supervised learning.\n***END OF PAGE 13***","image":[],"pageNum":13},{"SlideNum":14,"PageNum":14,"Title":"After being initially heralded as having significant promise the field of neural networks","Paragraph":"***START OF PAGE 14***\nAfter being initially heralded as having significant promise, the field of neural networks\nhas come in and out of fashion, particularly within the United States.  From the 1980s through\nthe mid-2000s, their challenge seemed to be that there were significant limitations to the\ntechnology that could not be easily fixed by using larger training datasets or through the\nintroduction of additional layers of “neurons.” However, in the mid-2000s, a small number of\nnew algorithmic approaches demonstrated the potential to enhance prediction through back\npropagation through multiple layers.  These neural networks increased their predictive power as\nthey were applied to larger and larger datasets, and were able to scale to an arbitrary level\n(among others, a key reference here is Hinton and Salakhutdinov (2006)).  These advances\nexhibited a “surprising” level of performance improvement, notably in the context of the\nImageNet visual recognition project competition pioneered by Fei-Fei Li at Stanford\n(Krizhevsky, Sutskever and Hinton, 2012).\nIV. How Might Different Fields within Artificial Intelligence Impact Innovation?\nDistinguishing between these three streams of AI is a critical first step towards\ndeveloping a better understanding of how AI is likely to influence the innovation process going\nforward, since the three differ significantly in their potential to be either GPTs or IMIs—or both.\nFirst, though a significant amount of public discussion of AI focuses on the potential for\nAI to achieve super-human performance over a wide range of human cognitive capabilities, it is\nimportant to note that, at least so far, the significant advances in AI have not been in the form of\nthe “general problem solver” approaches that were at the core of early work in symbolic systems\n(and that were the motivation for considerations of human reasoning such as the Turing test).\nInstead, recent advances in both robotics and in deep learning are by and large innovations that\nrequire a significant level of human planning and that apply to a relatively narrow domain of\nproblem-solving (e.g., face recognition, playing Go, picking up a particular object, etc.)  While it\nis of course possible that further breakthroughs will lead to a technology that can meaningfully\nmimic the nature of human subjective intelligence and emotion, the recent advances that have\nattracted scientific and commercial attention are well removed from these domains.\n***END OF PAGE 14***","title":"After being initially heralded as having significant promise the field of neural networks","slideNum":14,"paragraph":"***START OF PAGE 14***\nAfter being initially heralded as having significant promise, the field of neural networks\nhas come in and out of fashion, particularly within the United States.  From the 1980s through\nthe mid-2000s, their challenge seemed to be that there were significant limitations to the\ntechnology that could not be easily fixed by using larger training datasets or through the\nintroduction of additional layers of “neurons.” However, in the mid-2000s, a small number of\nnew algorithmic approaches demonstrated the potential to enhance prediction through back\npropagation through multiple layers.  These neural networks increased their predictive power as\nthey were applied to larger and larger datasets, and were able to scale to an arbitrary level\n(among others, a key reference here is Hinton and Salakhutdinov (2006)).  These advances\nexhibited a “surprising” level of performance improvement, notably in the context of the\nImageNet visual recognition project competition pioneered by Fei-Fei Li at Stanford\n(Krizhevsky, Sutskever and Hinton, 2012).\nIV. How Might Different Fields within Artificial Intelligence Impact Innovation?\nDistinguishing between these three streams of AI is a critical first step towards\ndeveloping a better understanding of how AI is likely to influence the innovation process going\nforward, since the three differ significantly in their potential to be either GPTs or IMIs—or both.\nFirst, though a significant amount of public discussion of AI focuses on the potential for\nAI to achieve super-human performance over a wide range of human cognitive capabilities, it is\nimportant to note that, at least so far, the significant advances in AI have not been in the form of\nthe “general problem solver” approaches that were at the core of early work in symbolic systems\n(and that were the motivation for considerations of human reasoning such as the Turing test).\nInstead, recent advances in both robotics and in deep learning are by and large innovations that\nrequire a significant level of human planning and that apply to a relatively narrow domain of\nproblem-solving (e.g., face recognition, playing Go, picking up a particular object, etc.)  While it\nis of course possible that further breakthroughs will lead to a technology that can meaningfully\nmimic the nature of human subjective intelligence and emotion, the recent advances that have\nattracted scientific and commercial attention are well removed from these domains.\n***END OF PAGE 14***","image":[],"pageNum":14},{"SlideNum":15,"PageNum":15,"Title":"Second though most economic and policy analysis of AI draws out consequences from","Paragraph":"***START OF PAGE 15***\nSecond, though most economic and policy analysis of AI draws out consequences from\nthe last two decades of automation to consider the future economic impact of AI (e.g., in job\ndisplacement for an ever-increasing number of tasks), it is important to emphasize that there is a\nsharp difference between the advances in robotics that were a primary focus of applications of AI\nresearch during the 2000s and the potential applications of deep learning which have come to the\nfore over the last few years.\nAs we suggested above, current advances in robotics are by and large associated with\napplications that are highly specialized and that are focused on end-user applications rather than\non the innovation process itself and these advances do not seem as of yet to have translated to a\nmore generally applicable IMI.  Robotics is therefore an area where we might focus on the\nimpact of innovation (improved performance) and diffusion (more widespread application) in\nterms of job displacement versus job enhancement.  We see limited evidence as yet of\nwidespread applications of robotics outside industrial automation, or of the scale of\nimprovements in the ability to sense, react to, and manipulate the physically environment that the\nuse of robotics outside manufacturing probably requires.  But there are exceptions: developments\nin the capabilities of “pick and place” robots and rapid progress in autonomous vehicles point to\nthe possibility for robotics to escape manufacturing and become much more broadly used.\nAdvances in robotics may well reveal this area of AI be a GPT, as defined by the classic criteria.\nSome research tools/IMIs based on algorithms have transformed the nature of research in\nsome fields, but have lacked generality.  These types of algorithmic research tools, based on a\nstatic set of program instructions, are a valuable IMI, but do not appear to have wide\napplicability outside a specific domain and do not qualify as GPTs.  For example, while far from\nperfect, powerful algorithms to scan brain images (so-called functional MRI imaging) have\ntransformed our understanding of the human brain, not only through the knowledge they have\ngenerated but also by establishing an entirely new paradigm and protocol for brain research.\nHowever, despite its role as a powerful IMI, fMRI lacks the type of general-purpose applicability\nthat has been associated with the most important GPTs.  In contrast, the latest advances in deep\nlearning have the potential to be both a general-purpose IMI and a classic GPT.\nThe following table summarizes these ideas:\n***END OF PAGE 15***","title":"Second though most economic and policy analysis of AI draws out consequences from","slideNum":15,"paragraph":"***START OF PAGE 15***\nSecond, though most economic and policy analysis of AI draws out consequences from\nthe last two decades of automation to consider the future economic impact of AI (e.g., in job\ndisplacement for an ever-increasing number of tasks), it is important to emphasize that there is a\nsharp difference between the advances in robotics that were a primary focus of applications of AI\nresearch during the 2000s and the potential applications of deep learning which have come to the\nfore over the last few years.\nAs we suggested above, current advances in robotics are by and large associated with\napplications that are highly specialized and that are focused on end-user applications rather than\non the innovation process itself and these advances do not seem as of yet to have translated to a\nmore generally applicable IMI.  Robotics is therefore an area where we might focus on the\nimpact of innovation (improved performance) and diffusion (more widespread application) in\nterms of job displacement versus job enhancement.  We see limited evidence as yet of\nwidespread applications of robotics outside industrial automation, or of the scale of\nimprovements in the ability to sense, react to, and manipulate the physically environment that the\nuse of robotics outside manufacturing probably requires.  But there are exceptions: developments\nin the capabilities of “pick and place” robots and rapid progress in autonomous vehicles point to\nthe possibility for robotics to escape manufacturing and become much more broadly used.\nAdvances in robotics may well reveal this area of AI be a GPT, as defined by the classic criteria.\nSome research tools/IMIs based on algorithms have transformed the nature of research in\nsome fields, but have lacked generality.  These types of algorithmic research tools, based on a\nstatic set of program instructions, are a valuable IMI, but do not appear to have wide\napplicability outside a specific domain and do not qualify as GPTs.  For example, while far from\nperfect, powerful algorithms to scan brain images (so-called functional MRI imaging) have\ntransformed our understanding of the human brain, not only through the knowledge they have\ngenerated but also by establishing an entirely new paradigm and protocol for brain research.\nHowever, despite its role as a powerful IMI, fMRI lacks the type of general-purpose applicability\nthat has been associated with the most important GPTs.  In contrast, the latest advances in deep\nlearning have the potential to be both a general-purpose IMI and a classic GPT.\nThe following table summarizes these ideas:\n***END OF PAGE 15***","image":[],"pageNum":15},{"SlideNum":16,"PageNum":16,"Title":"GeneralPurpose Technology","Paragraph":"***START OF PAGE 16***\nGeneral-Purpose Technology\nNO YES\nInvention of a\nMethod of Invention\nIndustrial Robots\n(e.g. Fanuc R2000)\n‘Sense & React” Robots\n(e.g. Autonomous vehicles)\nStatically-coded\nAlgorithmic Tools\n(e.g. fMRI)\nDeep Learning\nHow might the promise of deep learning as a general-purpose IMI be realized?  Deep\nlearning promises to be an enormously powerful new tool that allows for the unstructured\n“prediction” of physical or logical events in contexts where algorithms based on a static set of\nprogram instructions (such as classic statistical methods) perform poorly.  The development of\nthis new approach to prediction enables a new approach to undertaking scientific and technical\nresearch.  Rather than focusing on small well-characterized datasets or testing settings, it is now\npossible to proceed by identifying large pools of unstructured data which can be used to\ndynamically develop highly accurate predictions of technical and behavioral phenomena.  In\npioneering an unstructured approach to predictive drug candidate selection that brings together a\nvast array of previously disparate clinical and biophysical data, for example, Atomwise may\nfundamentally reshape the “ideas production function” in drug discovery.\nIf advances in deep learning do represent the arrival of a general-purpose IMI, it is clear\nthat there are likely to be very significant long-run economic, social, and technological\nconsequence.  First, as this new IMI diffuses across many application sectors, the resulting\nexplosion in technological opportunities and increased productivity of R&D seem likely to\ngenerate economic growth that can eclipse any near-term impact of AI on jobs, organizations,\nand productivity.  A more subtle implication of this point is that “past is not prologue”:  even if\nautomation over the recent past has resulted in job displacement (e.g., Acemoglu and Restrepo,\n2017a), AI is likely to have at least as important an impact through its ability to enhance the\npotential for “new tasks” (as in Acemoglu and Restrepo, 2017b).\nSecond, the arrival of a general-purpose IMI is a sufficiently uncommon occurrence that\nits impact could be profound for economic growth and its broader impact on society.  There have\n***END OF PAGE 16***","title":"GeneralPurpose Technology","slideNum":16,"paragraph":"***START OF PAGE 16***\nGeneral-Purpose Technology\nNO YES\nInvention of a\nMethod of Invention\nIndustrial Robots\n(e.g. Fanuc R2000)\n‘Sense & React” Robots\n(e.g. Autonomous vehicles)\nStatically-coded\nAlgorithmic Tools\n(e.g. fMRI)\nDeep Learning\nHow might the promise of deep learning as a general-purpose IMI be realized?  Deep\nlearning promises to be an enormously powerful new tool that allows for the unstructured\n“prediction” of physical or logical events in contexts where algorithms based on a static set of\nprogram instructions (such as classic statistical methods) perform poorly.  The development of\nthis new approach to prediction enables a new approach to undertaking scientific and technical\nresearch.  Rather than focusing on small well-characterized datasets or testing settings, it is now\npossible to proceed by identifying large pools of unstructured data which can be used to\ndynamically develop highly accurate predictions of technical and behavioral phenomena.  In\npioneering an unstructured approach to predictive drug candidate selection that brings together a\nvast array of previously disparate clinical and biophysical data, for example, Atomwise may\nfundamentally reshape the “ideas production function” in drug discovery.\nIf advances in deep learning do represent the arrival of a general-purpose IMI, it is clear\nthat there are likely to be very significant long-run economic, social, and technological\nconsequence.  First, as this new IMI diffuses across many application sectors, the resulting\nexplosion in technological opportunities and increased productivity of R&D seem likely to\ngenerate economic growth that can eclipse any near-term impact of AI on jobs, organizations,\nand productivity.  A more subtle implication of this point is that “past is not prologue”:  even if\nautomation over the recent past has resulted in job displacement (e.g., Acemoglu and Restrepo,\n2017a), AI is likely to have at least as important an impact through its ability to enhance the\npotential for “new tasks” (as in Acemoglu and Restrepo, 2017b).\nSecond, the arrival of a general-purpose IMI is a sufficiently uncommon occurrence that\nits impact could be profound for economic growth and its broader impact on society.  There have\n***END OF PAGE 16***","image":[],"pageNum":16},{"SlideNum":17,"PageNum":17,"Title":"been only a handful of previous generalpurpose IMIs and each of these has had an enormous","Paragraph":"***START OF PAGE 17***\nbeen only a handful of previous general-purpose IMIs and each of these has had an enormous\nimpact not primarily through their direct effects (e.g., spectacles, in the case of the invention of\noptical lenses) but through their ability to reshape the ideas production function itself (e.g.\ntelescopes and microscopes).  It would therefore be helpful to understand the extent to which\ndeep learning is, or will, causing researchers to significantly shift or reorient their approach in\norder to enhance research productivity (in the spirit of Jones (2009)).\nFinally, if deep learning does indeed prove to be a general-purpose IMI, it will be\nimportant to develop institutions and a policy environment that is conductive to enhancing\ninnovation through this approach, and to do so in a way that promotes competition and social\nwelfare.  A central concern here may be the interplay between a key input required for deep\nlearning—large unstructured databases that provide information about physical or logical\nevents—and the nature of competition.  While the underlying algorithms for deep learning are in\nthe public domain (and can and are being improved on rapidly), the data pools that are essential\nto generate predictions may be public or private, and access to them will depend on\norganizational boundaries, policy and institutions.  Because the performance of deep learning\nalgorithms depends critically on the training data that they are created from, it may be possible,\nin a particular application area, for a specific company (either an incumbent or start-up) gain a\nsignificant, persistent innovation advantage through their control over data that is independent of\ntraditional economies of scale or demand-side network effects.  This “competition for the\nmarket” is likely to have several consequences.  First, it creates incentives for duplicative racing\nto establish a data advantage in particular application sectors (say, search, autonomous driving,\nor cytology) followed by the establishment of durable barriers to entry that may be of significant\nconcern for competition policy.  Perhaps even more importantly, this kind of behavior could\nresult in a balkanization of data within each sector, not only reducing innovative productivity\nwithin the sector, but also reducing spillovers back to the deep learning GPT sector, and to other\napplication sectors.  This suggests that the proactive development of institutions and policies that\nencourage competition, data sharing, and openness is likely to be an important determinant of\neconomic gains from the development and application of deep learning.\nOur discussion so far has been largely speculative, and it would be useful to know\nwhether our claim that deep learning may be both a general-purpose IMI and a GPT, while\n***END OF PAGE 17***","title":"been only a handful of previous generalpurpose IMIs and each of these has had an enormous","slideNum":17,"paragraph":"***START OF PAGE 17***\nbeen only a handful of previous general-purpose IMIs and each of these has had an enormous\nimpact not primarily through their direct effects (e.g., spectacles, in the case of the invention of\noptical lenses) but through their ability to reshape the ideas production function itself (e.g.\ntelescopes and microscopes).  It would therefore be helpful to understand the extent to which\ndeep learning is, or will, causing researchers to significantly shift or reorient their approach in\norder to enhance research productivity (in the spirit of Jones (2009)).\nFinally, if deep learning does indeed prove to be a general-purpose IMI, it will be\nimportant to develop institutions and a policy environment that is conductive to enhancing\ninnovation through this approach, and to do so in a way that promotes competition and social\nwelfare.  A central concern here may be the interplay between a key input required for deep\nlearning—large unstructured databases that provide information about physical or logical\nevents—and the nature of competition.  While the underlying algorithms for deep learning are in\nthe public domain (and can and are being improved on rapidly), the data pools that are essential\nto generate predictions may be public or private, and access to them will depend on\norganizational boundaries, policy and institutions.  Because the performance of deep learning\nalgorithms depends critically on the training data that they are created from, it may be possible,\nin a particular application area, for a specific company (either an incumbent or start-up) gain a\nsignificant, persistent innovation advantage through their control over data that is independent of\ntraditional economies of scale or demand-side network effects.  This “competition for the\nmarket” is likely to have several consequences.  First, it creates incentives for duplicative racing\nto establish a data advantage in particular application sectors (say, search, autonomous driving,\nor cytology) followed by the establishment of durable barriers to entry that may be of significant\nconcern for competition policy.  Perhaps even more importantly, this kind of behavior could\nresult in a balkanization of data within each sector, not only reducing innovative productivity\nwithin the sector, but also reducing spillovers back to the deep learning GPT sector, and to other\napplication sectors.  This suggests that the proactive development of institutions and policies that\nencourage competition, data sharing, and openness is likely to be an important determinant of\neconomic gains from the development and application of deep learning.\nOur discussion so far has been largely speculative, and it would be useful to know\nwhether our claim that deep learning may be both a general-purpose IMI and a GPT, while\n***END OF PAGE 17***","image":[],"pageNum":17},{"SlideNum":18,"PageNum":18,"Title":"symbolic logic and robotics are probably not have any empirical basis  We turn in the next","Paragraph":"***START OF PAGE 18***\nsymbolic logic and robotics are probably not, have any empirical basis.  We turn in the next\nsection to a preliminary examination of the evolution of AI as revealed by bibliometric data, with\nan eye towards answering this question.\nV. Data\nThis analysis draws upon two distinct datasets, one that captures a set of AI publications\nfrom Thompson Reuters Web of Science, and another that identifies a set of AI patents issued by\nthe U.S. Patent and Trademark Office. In this section, we provide detail on the assembly of these\ndatasets and summary statistics for variables in the sample.\n. As previously discussed, peer-reviewed and public-domain literature on AI points to the\nexistence of three distinct fields within AI: robotics, learning systems and symbol systems, each\ncomprised of numerous subfields.  To track development of each of these using this data, we\nbegan by identifying the publications and patents falling into each of these three fields based on\nkeywords.  Appendix 1 lists the terms we used to define each field and identify the papers and\npatents belonging to it. .2  In short, the robotics field includes approaches in which a system\nengages with and responds to environmental conditions; the symbolic systems field attempts to\nrepresent complex concepts through logical manipulation of symbolic representations, and the\nlearning systems field processes data through analytical programs modeled on neurologic\nsystems.\nPublication Sample and Summary Statistics\nOur analysis focuses on journal articles and book publications through the Web of\nScience from 1955 to 2015.  We conducted a keyword search utilizing the keywords described in\nAppendix A (we tried several variants of these keywords and alternative algorithmic approaches\nbut this did not result in a meaningful difference in the publication set).   We are able to gather\ndetailed information about each publication, including publication year, journal information,\ntopical information, as well as author and institutional affiliations.\n2 Ironically enough, we relied upon human intelligence rather than machine learning to develop this classification\nsystem and apply it to this data set.\n***END OF PAGE 18***","title":"symbolic logic and robotics are probably not have any empirical basis  We turn in the next","slideNum":18,"paragraph":"***START OF PAGE 18***\nsymbolic logic and robotics are probably not, have any empirical basis.  We turn in the next\nsection to a preliminary examination of the evolution of AI as revealed by bibliometric data, with\nan eye towards answering this question.\nV. Data\nThis analysis draws upon two distinct datasets, one that captures a set of AI publications\nfrom Thompson Reuters Web of Science, and another that identifies a set of AI patents issued by\nthe U.S. Patent and Trademark Office. In this section, we provide detail on the assembly of these\ndatasets and summary statistics for variables in the sample.\n. As previously discussed, peer-reviewed and public-domain literature on AI points to the\nexistence of three distinct fields within AI: robotics, learning systems and symbol systems, each\ncomprised of numerous subfields.  To track development of each of these using this data, we\nbegan by identifying the publications and patents falling into each of these three fields based on\nkeywords.  Appendix 1 lists the terms we used to define each field and identify the papers and\npatents belonging to it. .2  In short, the robotics field includes approaches in which a system\nengages with and responds to environmental conditions; the symbolic systems field attempts to\nrepresent complex concepts through logical manipulation of symbolic representations, and the\nlearning systems field processes data through analytical programs modeled on neurologic\nsystems.\nPublication Sample and Summary Statistics\nOur analysis focuses on journal articles and book publications through the Web of\nScience from 1955 to 2015.  We conducted a keyword search utilizing the keywords described in\nAppendix A (we tried several variants of these keywords and alternative algorithmic approaches\nbut this did not result in a meaningful difference in the publication set).   We are able to gather\ndetailed information about each publication, including publication year, journal information,\ntopical information, as well as author and institutional affiliations.\n2 Ironically enough, we relied upon human intelligence rather than machine learning to develop this classification\nsystem and apply it to this data set.\n***END OF PAGE 18***","image":[],"pageNum":18},{"SlideNum":19,"PageNum":19,"Title":"This search yields  publications  We then code each publication into one of the","Paragraph":"***START OF PAGE 19***\nThis search yields 98,124 publications.  We then code each publication into one of the\nthree main fields of AI, as described above.  Overall, relative to an initial dataset of 98,124, we\nare able to uniquely classify 95,840 publications as symbolic systems, learning systems, robotics,\nor “general” AI (we drop papers that involve combinations of these three fields).  Table 1A\nreports the summary statistics for this sample.\nOf the 95,840 publication in the sample, 11,938 (12.5 percent) are classified as symbolic\nsystems, 58,853 (61.4 percent) as learning and 20,655 (21.6 percent) as robotics, with the\nremainder being in the general field of “artificial intelligence.”  To derive a better understanding\nof the factors that have shaped the evolution of AI, we create indicators for variables of interest\nincluding organization type (private versus academic), location type (US domestic versus\nInternational), and application type (computer science versus other application area, in addition\nto individual subject spaces, e.g. biology, materials science, medicine, physics, economics, etc.).\nWe identify organization type as academic if the organization of one of the authors on the\npublication is an academic institution. 81,998 publications (85.5 percent) and 13,842 (14.4\npercent) are produced by academic and private sector authors, respectively. We identify\npublication location as US domestic if one of the authors on the publication lists the United\nStates as his or her primary location. 22,436 publications (25 percent of the sample) are produced\ndomestically.\nWe also differentiate between subject matter. 44 percent of the publications are classified\nas Computer Science, with 56 percent classified as other applications. Summary statistics on the\nother applications are provided in Table 2A. The other subjects with the largest number of\npublications in the sample include Telecommunications (5.5 percent), Mathematics (4.2),\nNeurology (3.8), Chemistry (3.7), Physics (3.4), Biology (3.4), and Medicine (3.1).\nFinally, we create indicator variables to document publication quality, including journal\nquality (top 10, top 25 and top 50 journals by impact factor3) and a count variable for cumulative\ncitation counts. Less than one percent of publications are in a top 10 journal with two percent and\n10 percent in top 25 and top 50 journals. The average citation count for a publication in the\nsample is 4.9.\n3 The rankings are collected from Guide2Research, found here: http://www.guide2research.com/journals/\n***END OF PAGE 19***","title":"This search yields  publications  We then code each publication into one of the","slideNum":19,"paragraph":"***START OF PAGE 19***\nThis search yields 98,124 publications.  We then code each publication into one of the\nthree main fields of AI, as described above.  Overall, relative to an initial dataset of 98,124, we\nare able to uniquely classify 95,840 publications as symbolic systems, learning systems, robotics,\nor “general” AI (we drop papers that involve combinations of these three fields).  Table 1A\nreports the summary statistics for this sample.\nOf the 95,840 publication in the sample, 11,938 (12.5 percent) are classified as symbolic\nsystems, 58,853 (61.4 percent) as learning and 20,655 (21.6 percent) as robotics, with the\nremainder being in the general field of “artificial intelligence.”  To derive a better understanding\nof the factors that have shaped the evolution of AI, we create indicators for variables of interest\nincluding organization type (private versus academic), location type (US domestic versus\nInternational), and application type (computer science versus other application area, in addition\nto individual subject spaces, e.g. biology, materials science, medicine, physics, economics, etc.).\nWe identify organization type as academic if the organization of one of the authors on the\npublication is an academic institution. 81,998 publications (85.5 percent) and 13,842 (14.4\npercent) are produced by academic and private sector authors, respectively. We identify\npublication location as US domestic if one of the authors on the publication lists the United\nStates as his or her primary location. 22,436 publications (25 percent of the sample) are produced\ndomestically.\nWe also differentiate between subject matter. 44 percent of the publications are classified\nas Computer Science, with 56 percent classified as other applications. Summary statistics on the\nother applications are provided in Table 2A. The other subjects with the largest number of\npublications in the sample include Telecommunications (5.5 percent), Mathematics (4.2),\nNeurology (3.8), Chemistry (3.7), Physics (3.4), Biology (3.4), and Medicine (3.1).\nFinally, we create indicator variables to document publication quality, including journal\nquality (top 10, top 25 and top 50 journals by impact factor3) and a count variable for cumulative\ncitation counts. Less than one percent of publications are in a top 10 journal with two percent and\n10 percent in top 25 and top 50 journals. The average citation count for a publication in the\nsample is 4.9.\n3 The rankings are collected from Guide2Research, found here: http://www.guide2research.com/journals/\n***END OF PAGE 19***","image":[],"pageNum":19},{"SlideNum":20,"PageNum":20,"Title":"Patent Sample and Summary Statistics","Paragraph":"***START OF PAGE 20***\nPatent Sample and Summary Statistics\nWe undertake a similar approach for gathering a dataset of AI patents.  We start with the\npublic-use file of USPTO patents (Marco, Carley et al., 2015; Marco et al., 2015,), and filter the\ndata in two ways. First, we assemble a subset of data by filtering the USPTO Historical\nMasterfile on the U.S. Patent Classification System (USPC) number. 4  Specifically, USPC\nnumbers 706 and 901 represent “Artificial Intelligence” and “Robots,” respectively. Within\nUSPC 706, there are numerous subclasses including “fuzzy logic hardware,” “plural processing\nsystems,” “machine learning,” and “knowledge processing systems,” to name a few. We then use\nthe USPC subclass to identify patents in AI fields of symbolic systems, learning systems and\nrobotics. We drop patents prior to 1990, providing a sample of 7,347 patents through 2014.\nSecond, we assemble another subset of AI patents by conducting a title search on patents,\nwith the search terms being the same keywords used to identify academic publications in AI.5\nThis provides an additional 8,640 AI patents. We then allocate each patent into an AI field by\nassociating the relevant search term with one of the overarching fields. For example, a patent that\nis found through the search term “neural network,” is then classified as a “learning” patent.\nSome patents found through this search method will be duplicative of those identified by USPC\nsearch, i.e. the USPC class will be 706 or 901. We drop those duplicates. Together these two\nsubsets create a sample of 13,615 unique AI patents. Summary statistics are provided in Table\nIn contrast to the distribution of learning systems, symbolic systems and robotics in the\npublication data, the three fields are more evenly distributed in the patent data: 3,832 (28\npercent) learning system patents, 3,930 (29 percent) symbolic system patents, and 5,524 (40\npercent) robotics patents. The remaining patents are broadly classified only as AI.\nUsing ancillary datasets to the USPTO Historical Masterfile, we are able to integrate\nvariables of interest related to organization type, location, and application space. For example,\n4 We utilized data from the Historical Patent Data Files. The complete (un-filtered) data sets from which we derived\nour data set are available here: https://www.uspto.gov/learning-and-resources/electronic-data-products/historical-\npatent-data-files\n5 We utilized data from the Document ID Dataset that is complementary to Patent Assignment Data available on the\nUSPTO website. The complete (un-filtered) data sets from which we derived our data set are available here:\nhttps://www.uspto.gov/learning-and-resources/electronic-data-products/patent-assignment-dataset\n***END OF PAGE 20***","title":"Patent Sample and Summary Statistics","slideNum":20,"paragraph":"***START OF PAGE 20***\nPatent Sample and Summary Statistics\nWe undertake a similar approach for gathering a dataset of AI patents.  We start with the\npublic-use file of USPTO patents (Marco, Carley et al., 2015; Marco et al., 2015,), and filter the\ndata in two ways. First, we assemble a subset of data by filtering the USPTO Historical\nMasterfile on the U.S. Patent Classification System (USPC) number. 4  Specifically, USPC\nnumbers 706 and 901 represent “Artificial Intelligence” and “Robots,” respectively. Within\nUSPC 706, there are numerous subclasses including “fuzzy logic hardware,” “plural processing\nsystems,” “machine learning,” and “knowledge processing systems,” to name a few. We then use\nthe USPC subclass to identify patents in AI fields of symbolic systems, learning systems and\nrobotics. We drop patents prior to 1990, providing a sample of 7,347 patents through 2014.\nSecond, we assemble another subset of AI patents by conducting a title search on patents,\nwith the search terms being the same keywords used to identify academic publications in AI.5\nThis provides an additional 8,640 AI patents. We then allocate each patent into an AI field by\nassociating the relevant search term with one of the overarching fields. For example, a patent that\nis found through the search term “neural network,” is then classified as a “learning” patent.\nSome patents found through this search method will be duplicative of those identified by USPC\nsearch, i.e. the USPC class will be 706 or 901. We drop those duplicates. Together these two\nsubsets create a sample of 13,615 unique AI patents. Summary statistics are provided in Table\nIn contrast to the distribution of learning systems, symbolic systems and robotics in the\npublication data, the three fields are more evenly distributed in the patent data: 3,832 (28\npercent) learning system patents, 3,930 (29 percent) symbolic system patents, and 5,524 (40\npercent) robotics patents. The remaining patents are broadly classified only as AI.\nUsing ancillary datasets to the USPTO Historical Masterfile, we are able to integrate\nvariables of interest related to organization type, location, and application space. For example,\n4 We utilized data from the Historical Patent Data Files. The complete (un-filtered) data sets from which we derived\nour data set are available here: https://www.uspto.gov/learning-and-resources/electronic-data-products/historical-\npatent-data-files\n5 We utilized data from the Document ID Dataset that is complementary to Patent Assignment Data available on the\nUSPTO website. The complete (un-filtered) data sets from which we derived our data set are available here:\nhttps://www.uspto.gov/learning-and-resources/electronic-data-products/patent-assignment-dataset\n***END OF PAGE 20***","image":[],"pageNum":20},{"SlideNum":21,"PageNum":21,"Title":"Patent Assignment Data tracks ownership of patents across time Our interest in this analysis","Paragraph":"***START OF PAGE 21***\nPatent Assignment Data tracks ownership of patents across time. Our interest in this analysis\nrelates to upstream innovative work, and for this reason, we capture the initial patent assignee by\norganization for each patent in our sample. This data enables the creation of indicator variables\nfor organization type and location. We create an indicator for academic organization type by\nsearching the name of the assignee for words relating to academic institutions, e.g. “University”,\n“College” or “Institution.” We do the same for private sector organizations, searching for “corp”,\n“business”, “inc”, or “co”, to name a few. We also search for the same words or abbreviations\nutilized in other languages, e.g. “S.p.A.” Only seven percent of the sample is awarded to\nacademic organizations, while 91 percent is awarded to private entities. The remaining patents\nare assigned to government entities, e.g. U.S. Department of Defense.\nSimilarly, we create indicator variables for patents assigned to U.S. firms and\ninternational firms, based on the country of the assignee. The international firm data can also be\nmore narrowly identified by specific country (e.g. Canada) or region (e.g. European Union). 59\npercent of our patent sample is assigned to U.S. domestic firms, while 41 percent is assigned to\ninternational firms. Next to the United States, firms from non-Chinese, Asian nations account for\n28 percent of patents in the sample. Firms from Canada are assigned 1.2 percent of the patents,\nand firms from China, 0.4 percent.\nAdditionally, the USPTO data includes NBER classification and sub-classification for\neach patent (Hall, Jaffe and Trajtenberg (2001); Marco, Carley, et al., (2015)). These sub-\nclassifications provide some granular detail about the application sector for which the patent is\nintended.  We create indicator variables for NBER sub-classifications related to chemicals\n(NBER sub-class 11, 12, 13, 14, 15, 19), communications (21), computer hardware and software\n(22), computer science peripherals (23), data and storage (24), business software (25), medical\nfields (31, 32, 33, and 39), electronics fields (41, 42, 43, 44, 45, 46, and 49), automotive fields\n(53, 54, 55), mechanical fields (51, 52, 59), and other fields (remaining). The vast majority of\nthese patents (71 percent) are in NBER subclass 22, Computer Hardware and Software.\nSummary Statistics of the distribution of patents across application sectors are provided in Table\n***END OF PAGE 21***","title":"Patent Assignment Data tracks ownership of patents across time Our interest in this analysis","slideNum":21,"paragraph":"***START OF PAGE 21***\nPatent Assignment Data tracks ownership of patents across time. Our interest in this analysis\nrelates to upstream innovative work, and for this reason, we capture the initial patent assignee by\norganization for each patent in our sample. This data enables the creation of indicator variables\nfor organization type and location. We create an indicator for academic organization type by\nsearching the name of the assignee for words relating to academic institutions, e.g. “University”,\n“College” or “Institution.” We do the same for private sector organizations, searching for “corp”,\n“business”, “inc”, or “co”, to name a few. We also search for the same words or abbreviations\nutilized in other languages, e.g. “S.p.A.” Only seven percent of the sample is awarded to\nacademic organizations, while 91 percent is awarded to private entities. The remaining patents\nare assigned to government entities, e.g. U.S. Department of Defense.\nSimilarly, we create indicator variables for patents assigned to U.S. firms and\ninternational firms, based on the country of the assignee. The international firm data can also be\nmore narrowly identified by specific country (e.g. Canada) or region (e.g. European Union). 59\npercent of our patent sample is assigned to U.S. domestic firms, while 41 percent is assigned to\ninternational firms. Next to the United States, firms from non-Chinese, Asian nations account for\n28 percent of patents in the sample. Firms from Canada are assigned 1.2 percent of the patents,\nand firms from China, 0.4 percent.\nAdditionally, the USPTO data includes NBER classification and sub-classification for\neach patent (Hall, Jaffe and Trajtenberg (2001); Marco, Carley, et al., (2015)). These sub-\nclassifications provide some granular detail about the application sector for which the patent is\nintended.  We create indicator variables for NBER sub-classifications related to chemicals\n(NBER sub-class 11, 12, 13, 14, 15, 19), communications (21), computer hardware and software\n(22), computer science peripherals (23), data and storage (24), business software (25), medical\nfields (31, 32, 33, and 39), electronics fields (41, 42, 43, 44, 45, 46, and 49), automotive fields\n(53, 54, 55), mechanical fields (51, 52, 59), and other fields (remaining). The vast majority of\nthese patents (71 percent) are in NBER subclass 22, Computer Hardware and Software.\nSummary Statistics of the distribution of patents across application sectors are provided in Table\n***END OF PAGE 21***","image":[],"pageNum":21},{"SlideNum":22,"PageNum":22,"Title":"VI Deep Learning as a GPT  An Exploratory Empirical Analysis","Paragraph":"***START OF PAGE 22***\nVI. Deep Learning as a GPT:  An Exploratory Empirical Analysis\nThese data allow us to begin examining the claim that the technologies of deep learning\nmay be the nucleus of a general-purpose invention for the method of invention.\nWe begin in Figures 1A and 1B with a simple description of the evolution over time of\nthe three main fields identified in the corpus of patents and papers.  The first insight is that the\noverall field of AI has experienced sharp growth since 1990.  While there are only a small\nhandful of papers (less than a hundred per year) at the beginning of the period, each of the three\nfields now generates more than a thousand papers per year.  At the same time, there is a striking\ndivergence in activity across fields:  each start from a similar base, but there is a steady increase\nin the deep learning publications relative to robotics and symbolic systems, particularly after\n2009.   Interestingly, at least through the end of 2014, there is more similarity in the patterns for\nall three fields in terms of patenting, with robotics patenting continuing to hold a lead over\nlearning and symbolic systems.  However, there does seem to be an acceleration of learning-\noriented patents in the last few years of the sample, and so there may be a relative shift towards\nlearning over the last few years which will manifest itself over time as publication and\nexamination lags work their way through.\nWithin the publication data, there are striking variations across geographies. Figure 2A\nshows the overall growth in learning publications for the US versus rest-of-world, and Figure 2B\nmaps the fraction of publications within each geography that are learning related.  In the US on\nlearning is far more variable. Prior to 2000 the US has a roughly equivalent share of learning\nrelated publications, but the US then falls significantly behind, only catching up again around\n2013.  This is consistent with the suggestion in qualitative histories of AI that that learning\nresearch has had a “faddish” quality in the US, with the additional insight that the rest of the\nworld (notably Canada) seems to have taken advantage of this inconsistent focus in the United\nStates to develop capabilities and comparative advantage in this field.\nWith these broad patterns in mind, we turn to our key empirical exercise:  whether in the\nlate 2000s deep learning shifted more towards “application-oriented” research than either\nrobotics or symbolic systems. We begin in Figure 3 with a simple graph that examines the\nnumber of publications over time (across all three fields) in computer science journals versus\napplication-oriented outlets.  While there has actually been a stagnation (even a small decline) in\n***END OF PAGE 22***","title":"VI Deep Learning as a GPT  An Exploratory Empirical Analysis","slideNum":22,"paragraph":"***START OF PAGE 22***\nVI. Deep Learning as a GPT:  An Exploratory Empirical Analysis\nThese data allow us to begin examining the claim that the technologies of deep learning\nmay be the nucleus of a general-purpose invention for the method of invention.\nWe begin in Figures 1A and 1B with a simple description of the evolution over time of\nthe three main fields identified in the corpus of patents and papers.  The first insight is that the\noverall field of AI has experienced sharp growth since 1990.  While there are only a small\nhandful of papers (less than a hundred per year) at the beginning of the period, each of the three\nfields now generates more than a thousand papers per year.  At the same time, there is a striking\ndivergence in activity across fields:  each start from a similar base, but there is a steady increase\nin the deep learning publications relative to robotics and symbolic systems, particularly after\n2009.   Interestingly, at least through the end of 2014, there is more similarity in the patterns for\nall three fields in terms of patenting, with robotics patenting continuing to hold a lead over\nlearning and symbolic systems.  However, there does seem to be an acceleration of learning-\noriented patents in the last few years of the sample, and so there may be a relative shift towards\nlearning over the last few years which will manifest itself over time as publication and\nexamination lags work their way through.\nWithin the publication data, there are striking variations across geographies. Figure 2A\nshows the overall growth in learning publications for the US versus rest-of-world, and Figure 2B\nmaps the fraction of publications within each geography that are learning related.  In the US on\nlearning is far more variable. Prior to 2000 the US has a roughly equivalent share of learning\nrelated publications, but the US then falls significantly behind, only catching up again around\n2013.  This is consistent with the suggestion in qualitative histories of AI that that learning\nresearch has had a “faddish” quality in the US, with the additional insight that the rest of the\nworld (notably Canada) seems to have taken advantage of this inconsistent focus in the United\nStates to develop capabilities and comparative advantage in this field.\nWith these broad patterns in mind, we turn to our key empirical exercise:  whether in the\nlate 2000s deep learning shifted more towards “application-oriented” research than either\nrobotics or symbolic systems. We begin in Figure 3 with a simple graph that examines the\nnumber of publications over time (across all three fields) in computer science journals versus\napplication-oriented outlets.  While there has actually been a stagnation (even a small decline) in\n***END OF PAGE 22***","image":[],"pageNum":22},{"SlideNum":23,"PageNum":23,"Title":"the overall number of AI publications in computer science journals there has been a dramatic","Paragraph":"***START OF PAGE 23***\nthe overall number of AI publications in computer science journals, there has been a dramatic\nincrease in the number of AI-related publications in application-oriented outlets.  By the end of\n2015, we estimate that nearly 2/3 of all publications in AI were in fields beyond computer\nscience.\nIn Figure 4 we then look at this division by field.  Several patterns are worthy of note.\nFirst, as earlier, we can see the relative growth through 2009 of publications in learning versus\nthe two other fields. Also, consistent with more qualitative accounts of the fields, we see the\nrelative stagnation of symbolic systems research relative to robotics and learning.  But, after\n2009, there is a significant increase in application publications in both robotics and learning, but\nthat the learning boost is both steeper and more long-lived.  Over the course of just seven years,\nlearning-oriented application publications more than double in number, and now represent just\nunder 50% of all AI publications.6\nThese patterns are if anything even more striking if one disaggregates them by the\ngeographic origin of the publication.  In Figure 5, we at rates of publication in computer science\nversus applications for the US versus rest-of-world.  The striking upward swing in AI application\npapers that begins in 2009 turns out to be overwhelmingly driven by publications ex US, though\nUS researchers begin a period of catch-up at an accelerating pace towards the final few years of\nthe sample.\nFinally, we look at how publications have varied across application sectors over time.  In\nTable 3, we examine the number of publications by application field in each of the three areas of\nAI across two three-year cohorts (2004-2006 and 2013-2015).  There are a number of patterns of\ninterest.  First, and most importantly, in a range of application fields including medicine,\nradiology and economics, there is a large relative increase in learning-oriented publications\nrelative to robotics and symbolic systems.  A number of other sectors, including neuroscience\nand biology, realize a large increase in both learning-oriented research as well as other AI fields.\nThere are also some more basic fields such as mathematics that have experienced a relative\ndecline in publications (indeed, learning-oriented publications in mathematics experienced a\n6 The precise number of publications for 2015 are estimated from the experience of the first nine months (the Web\nof Science data run through September 30, 2015).   We apply a linear multiplier for the remaining three months (i.e.,\nestimating each category by 4/3).\n***END OF PAGE 23***","title":"the overall number of AI publications in computer science journals there has been a dramatic","slideNum":23,"paragraph":"***START OF PAGE 23***\nthe overall number of AI publications in computer science journals, there has been a dramatic\nincrease in the number of AI-related publications in application-oriented outlets.  By the end of\n2015, we estimate that nearly 2/3 of all publications in AI were in fields beyond computer\nscience.\nIn Figure 4 we then look at this division by field.  Several patterns are worthy of note.\nFirst, as earlier, we can see the relative growth through 2009 of publications in learning versus\nthe two other fields. Also, consistent with more qualitative accounts of the fields, we see the\nrelative stagnation of symbolic systems research relative to robotics and learning.  But, after\n2009, there is a significant increase in application publications in both robotics and learning, but\nthat the learning boost is both steeper and more long-lived.  Over the course of just seven years,\nlearning-oriented application publications more than double in number, and now represent just\nunder 50% of all AI publications.6\nThese patterns are if anything even more striking if one disaggregates them by the\ngeographic origin of the publication.  In Figure 5, we at rates of publication in computer science\nversus applications for the US versus rest-of-world.  The striking upward swing in AI application\npapers that begins in 2009 turns out to be overwhelmingly driven by publications ex US, though\nUS researchers begin a period of catch-up at an accelerating pace towards the final few years of\nthe sample.\nFinally, we look at how publications have varied across application sectors over time.  In\nTable 3, we examine the number of publications by application field in each of the three areas of\nAI across two three-year cohorts (2004-2006 and 2013-2015).  There are a number of patterns of\ninterest.  First, and most importantly, in a range of application fields including medicine,\nradiology and economics, there is a large relative increase in learning-oriented publications\nrelative to robotics and symbolic systems.  A number of other sectors, including neuroscience\nand biology, realize a large increase in both learning-oriented research as well as other AI fields.\nThere are also some more basic fields such as mathematics that have experienced a relative\ndecline in publications (indeed, learning-oriented publications in mathematics experienced a\n6 The precise number of publications for 2015 are estimated from the experience of the first nine months (the Web\nof Science data run through September 30, 2015).   We apply a linear multiplier for the remaining three months (i.e.,\nestimating each category by 4/3).\n***END OF PAGE 23***","image":[],"pageNum":23},{"SlideNum":24,"PageNum":24,"Title":"small absolute decline a striking different relative to most other fields in the sample  Overall","Paragraph":"***START OF PAGE 24***\nsmall absolute decline, a striking different relative to most other fields in the sample).  Overall,\nthough it would be useful to identify more precisely the type of research that is being conducted\nand what is happening at the level of particular subfields, these results are consistent with our\nbroader hypothesis that, alongside the overall growth of AI, learning-oriented research may\nrepresent a general-purpose technology that is now beginning to be exploited far more\nsystematically across a wide range of application sectors.\nTogether, these preliminary findings provide some direct empirical evidence for at least\none of our hypotheses: learning-oriented AI seems to have some of the signature hallmarks of a\ngeneral-purpose technology.  Bibliometric indicators of innovation show that it is rapidly\ndeveloping, and is being applied in many sectors—and these application sectors themselves\ninclude some of the most technologically dynamic parts of the economy.  This preliminary\nanalysis does not trace out the important knowledge spillovers between innovation in the GPT\nand innovation and application sectors, but it is probably far too early to look for evidence of\nthis.\nVII. Deep Learning as a General-Purpose Invention in the Method of Invention:\nConsiderations for Organizations, Institutions and Policy\nWith these results in mind, we now consider the potential implications for innovation and\ninnovation policy if deep learning is indeed a general-purpose technology (GPT) and/or a\ngeneral-purpose invention in the method of invention (IMI). If deep learning is merely a GPT, it\nis likely to generate innovation across a range of applications (with potential for spillovers both\nback to the learning GPT and also to other application sectors) but will not itself change the\nnature of the innovation production function.  If it is also a general purpose IMI, we would\nexpect it to have an even larger impact on economy-wide innovation, growth, and productivity as\ndynamics play out—and to trigger even more severe short run disruptions of labor markets and\nthe internal structure of organizations.\nWidespread use of deep learning as a research tool implies a shift towards investigative\napproaches that use large datasets to generate predictions for physical and logical events that\nhave previously resisted systematic empirical scrutiny.  These data are likely to have three\n***END OF PAGE 24***","title":"small absolute decline a striking different relative to most other fields in the sample  Overall","slideNum":24,"paragraph":"***START OF PAGE 24***\nsmall absolute decline, a striking different relative to most other fields in the sample).  Overall,\nthough it would be useful to identify more precisely the type of research that is being conducted\nand what is happening at the level of particular subfields, these results are consistent with our\nbroader hypothesis that, alongside the overall growth of AI, learning-oriented research may\nrepresent a general-purpose technology that is now beginning to be exploited far more\nsystematically across a wide range of application sectors.\nTogether, these preliminary findings provide some direct empirical evidence for at least\none of our hypotheses: learning-oriented AI seems to have some of the signature hallmarks of a\ngeneral-purpose technology.  Bibliometric indicators of innovation show that it is rapidly\ndeveloping, and is being applied in many sectors—and these application sectors themselves\ninclude some of the most technologically dynamic parts of the economy.  This preliminary\nanalysis does not trace out the important knowledge spillovers between innovation in the GPT\nand innovation and application sectors, but it is probably far too early to look for evidence of\nthis.\nVII. Deep Learning as a General-Purpose Invention in the Method of Invention:\nConsiderations for Organizations, Institutions and Policy\nWith these results in mind, we now consider the potential implications for innovation and\ninnovation policy if deep learning is indeed a general-purpose technology (GPT) and/or a\ngeneral-purpose invention in the method of invention (IMI). If deep learning is merely a GPT, it\nis likely to generate innovation across a range of applications (with potential for spillovers both\nback to the learning GPT and also to other application sectors) but will not itself change the\nnature of the innovation production function.  If it is also a general purpose IMI, we would\nexpect it to have an even larger impact on economy-wide innovation, growth, and productivity as\ndynamics play out—and to trigger even more severe short run disruptions of labor markets and\nthe internal structure of organizations.\nWidespread use of deep learning as a research tool implies a shift towards investigative\napproaches that use large datasets to generate predictions for physical and logical events that\nhave previously resisted systematic empirical scrutiny.  These data are likely to have three\n***END OF PAGE 24***","image":[],"pageNum":24},{"SlideNum":25,"PageNum":25,"Title":"sources prior knowledge as in the case of learning of prior literatures by IBMs Watson","Paragraph":"***START OF PAGE 25***\nsources: prior knowledge (as in the case of “learning” of prior literatures by IBM’s Watson),\nonline transactions (e.g., search or online purchasing behavior) and physical events (e.g., the\noutput from various types of sensors or geolocation data) What would this imply for the\nappropriate organization of innovation, the institutions we have for training and conducting\nresearch over time, and for policy, particularly as we think about private incentives to maintain\nproprietary datasets and application-specific algorithms?\nThe Management and Organization of Innovation\nPerhaps most immediately, the rise of general-purpose predictive analytics using large\ndatasets seems likely to result in a substitution towards capital and away from labor in the\nresearch production process.  Many types of R&D and innovation more generally are effectively\nproblems of labor-intensive search with high marginal cost per search (Evenson and Kislev,\n1975, among others).  The development of deep learning holds out the promise of sharply\nreduced marginal search costs, inducing R&D organizations to substitute away from highly-\nskilled labor towards fixed cost investments in AI. These investments are likely to improve\nperformance in existing “search intensive” research projects, as well as to open up new\nopportunities to investigate social and physical phenomena that have previously been considered\nintractable or even as beyond the domain of systematic scientific and empirical research.\nIt is possible that the ability to substitute away from specialized labor and towards capital\n(that in principle could be rented or shared) may lower the “barriers to entry” in certain scientific\nor research fields—particularly those in which the necessary data and algorithms are freely\navailable—while erecting new barriers to entry in other areas (e.g. by restricting access to data\nand algorithms).  As of yet, there are few if any organized markets for “trained” research tools or\nservices based on deep learning, and few standards to evaluate alternatives.  Our analysis\nsuggests that the development of markets for shared AI services and the widespread availability\nof relevant data may be a necessary precursor to the broad adoption and dissemination of deep\nlearning.\nAt the same time, the arrival of this new research paradigm is likely to require a\nsignificant shift in the management of innovation itself.  For example, it is possible that the\ndemocratization of innovation will also be accompanied by a lack of investment by individual\nresearchers in specialized research skills and specialized expertise in any given area, reducing the\n***END OF PAGE 25***","title":"sources prior knowledge as in the case of learning of prior literatures by IBMs Watson","slideNum":25,"paragraph":"***START OF PAGE 25***\nsources: prior knowledge (as in the case of “learning” of prior literatures by IBM’s Watson),\nonline transactions (e.g., search or online purchasing behavior) and physical events (e.g., the\noutput from various types of sensors or geolocation data) What would this imply for the\nappropriate organization of innovation, the institutions we have for training and conducting\nresearch over time, and for policy, particularly as we think about private incentives to maintain\nproprietary datasets and application-specific algorithms?\nThe Management and Organization of Innovation\nPerhaps most immediately, the rise of general-purpose predictive analytics using large\ndatasets seems likely to result in a substitution towards capital and away from labor in the\nresearch production process.  Many types of R&D and innovation more generally are effectively\nproblems of labor-intensive search with high marginal cost per search (Evenson and Kislev,\n1975, among others).  The development of deep learning holds out the promise of sharply\nreduced marginal search costs, inducing R&D organizations to substitute away from highly-\nskilled labor towards fixed cost investments in AI. These investments are likely to improve\nperformance in existing “search intensive” research projects, as well as to open up new\nopportunities to investigate social and physical phenomena that have previously been considered\nintractable or even as beyond the domain of systematic scientific and empirical research.\nIt is possible that the ability to substitute away from specialized labor and towards capital\n(that in principle could be rented or shared) may lower the “barriers to entry” in certain scientific\nor research fields—particularly those in which the necessary data and algorithms are freely\navailable—while erecting new barriers to entry in other areas (e.g. by restricting access to data\nand algorithms).  As of yet, there are few if any organized markets for “trained” research tools or\nservices based on deep learning, and few standards to evaluate alternatives.  Our analysis\nsuggests that the development of markets for shared AI services and the widespread availability\nof relevant data may be a necessary precursor to the broad adoption and dissemination of deep\nlearning.\nAt the same time, the arrival of this new research paradigm is likely to require a\nsignificant shift in the management of innovation itself.  For example, it is possible that the\ndemocratization of innovation will also be accompanied by a lack of investment by individual\nresearchers in specialized research skills and specialized expertise in any given area, reducing the\n***END OF PAGE 25***","image":[],"pageNum":25},{"SlideNum":26,"PageNum":26,"Title":"level of theoretical or technical depth in the work force  This shift away from careeroriented","Paragraph":"***START OF PAGE 26***\nlevel of theoretical or technical depth in the work force.  This shift away from career-oriented\nresearch trajectories towards the ability to derive new findings based on deep learning may\nundermine long-term incentives for breakthrough research that can only be conducted by people\nwho are at the research frontier.  There is also the possibility that the large scale replacement of\nskilled technical labor in the research sector by AI will “break science” in some fields by\ndisrupting the career ladders and labor markets that support the relatively long periods of training\nand education required in many scientific and technical occupations.\nFinally, it is possible that deep learning will change the nature of scientific and technical\nadvance itself.  Many fields of science and engineering are driven by a mode of inquiry that\nfocuses on identifying a relatively small number of causal drivers of underlying phenomena built\nupon an underlying theory (the parsimony principle as restated by Einstein states that theory\nshould be “as simple as possible but no simpler.”)   However, deep learning offers an alternative\nparadigm based on the ability to predict complex multi-causal phenomena using a “black box”\napproach that abstracts away from underlying causes but that does allow for a singular prediction\nindex that can yield sharp insight.  De-emphasizing the understanding of causal mechanisms and\nabstract relationships may come at a cost: many major steps forward in science involve the\nability to leverage an understanding of “big picture” theoretical structure to make sense of, of\nrecognize the implications of, smaller discoveries.  For example, it is easy to imagine a deep\nlearning system trained on a large amount of x-ray diffraction data quickly “discovering” the\ndouble helix structure of DNA at very low marginal cost, but it would likely require human\njudgment and insight about a much broader biological context to notice that the proposed\nstructure suggests a direct mechanism for heredity.\nInnovation and Competition Policy and Institutions\nA second area of impact, beyond the organization of individual research projects or the\nnature of what counts as “science” in a particular field, will be on the appropriate design and\ngovernance of institutions governing the innovation process.  Three implications stand out.\nFirst, as discussed above, research over the past two decades has emphasized the\nimportant role played by institutions that encourage cumulative knowledge production through\nlow-cost independent access to research tools, materials and data (Furman and Stern, 2012;\nMurray, et al, 2015). However to date there has only been a modest level of attention to the\n***END OF PAGE 26***","title":"level of theoretical or technical depth in the work force  This shift away from careeroriented","slideNum":26,"paragraph":"***START OF PAGE 26***\nlevel of theoretical or technical depth in the work force.  This shift away from career-oriented\nresearch trajectories towards the ability to derive new findings based on deep learning may\nundermine long-term incentives for breakthrough research that can only be conducted by people\nwho are at the research frontier.  There is also the possibility that the large scale replacement of\nskilled technical labor in the research sector by AI will “break science” in some fields by\ndisrupting the career ladders and labor markets that support the relatively long periods of training\nand education required in many scientific and technical occupations.\nFinally, it is possible that deep learning will change the nature of scientific and technical\nadvance itself.  Many fields of science and engineering are driven by a mode of inquiry that\nfocuses on identifying a relatively small number of causal drivers of underlying phenomena built\nupon an underlying theory (the parsimony principle as restated by Einstein states that theory\nshould be “as simple as possible but no simpler.”)   However, deep learning offers an alternative\nparadigm based on the ability to predict complex multi-causal phenomena using a “black box”\napproach that abstracts away from underlying causes but that does allow for a singular prediction\nindex that can yield sharp insight.  De-emphasizing the understanding of causal mechanisms and\nabstract relationships may come at a cost: many major steps forward in science involve the\nability to leverage an understanding of “big picture” theoretical structure to make sense of, of\nrecognize the implications of, smaller discoveries.  For example, it is easy to imagine a deep\nlearning system trained on a large amount of x-ray diffraction data quickly “discovering” the\ndouble helix structure of DNA at very low marginal cost, but it would likely require human\njudgment and insight about a much broader biological context to notice that the proposed\nstructure suggests a direct mechanism for heredity.\nInnovation and Competition Policy and Institutions\nA second area of impact, beyond the organization of individual research projects or the\nnature of what counts as “science” in a particular field, will be on the appropriate design and\ngovernance of institutions governing the innovation process.  Three implications stand out.\nFirst, as discussed above, research over the past two decades has emphasized the\nimportant role played by institutions that encourage cumulative knowledge production through\nlow-cost independent access to research tools, materials and data (Furman and Stern, 2012;\nMurray, et al, 2015). However to date there has only been a modest level of attention to the\n***END OF PAGE 26***","image":[],"pageNum":26},{"SlideNum":27,"PageNum":27,"Title":"questions of transparency and replicability within the deep learning community  Grassroots","Paragraph":"***START OF PAGE 27***\nquestions of transparency and replicability within the deep learning community.  Grassroots\ninitiatives to encourage openness organized through online hubs and communities are to be\nwelcomed.  But it is useful to emphasize that there is likely to be a significant gap between the\nprivate and social incentives to share and aggregate data—even among academic researchers or\nprivate sector research communities.  One implication of this divergence may be that to the\ndegree any single research result depends on the aggregation of data from many sources, it will\nbe important to develop rules of credit and attribution, as well as to develop mechanisms to\nreplicate the results.\nThis implies that it will be particularly important to pay attention to the design and\nenforcement of formal intellectual property rights.  On the one hand it will be important to think\ncarefully about the laws that currently surround the ownership of data. Should the data about e.g.\nmy shopping and travel behavior belong to me or to the search engine or ride sharing company\nthat I use? Might consumers have a strong collective interest in ensuring that these data (suitably\nblinded, of course) are in the public domain, so that many companies can use them in the pursuit\nof innovation?\nOn the other, the advent of deep learning has significant implications for the patent\nsystem.  Though there has so far been relatively little patenting of deep learning innovations,\nhistorical episodes such as the discovery and attempted wholesale patenting of express sequence\ntags and other kinds of genetic data suggests that breakthroughs in research tools—often\ncombined with a lack of capacity at patent offices and conflicting court decisions—can result in\nlong periods of uncertainty that has hampered the issuing of new patents, and this in turn has led\nto lower research productivity and less competition.  Deep learning also presents difficult\nquestions of legal doctrine for patent systems that have been built around the idea of creative\nauthors and inventors.  For example, “inventorship” has a specific meaning in patent law, with\nvery important implications for ownership and control of the claimed invention.  Can an AI\nsystem be an inventor in the sense envisaged by the drafters of the US Constitution?  Similarly,\nstandards for determining the size of the inventive step required to obtain a patent are driven by a\ndetermination of whether the claimed invention would or would not be obvious to a “person\nhaving ordinary skill in the art.”  Who this “person” might be, and what constitutes “ordinary\n***END OF PAGE 27***","title":"questions of transparency and replicability within the deep learning community  Grassroots","slideNum":27,"paragraph":"***START OF PAGE 27***\nquestions of transparency and replicability within the deep learning community.  Grassroots\ninitiatives to encourage openness organized through online hubs and communities are to be\nwelcomed.  But it is useful to emphasize that there is likely to be a significant gap between the\nprivate and social incentives to share and aggregate data—even among academic researchers or\nprivate sector research communities.  One implication of this divergence may be that to the\ndegree any single research result depends on the aggregation of data from many sources, it will\nbe important to develop rules of credit and attribution, as well as to develop mechanisms to\nreplicate the results.\nThis implies that it will be particularly important to pay attention to the design and\nenforcement of formal intellectual property rights.  On the one hand it will be important to think\ncarefully about the laws that currently surround the ownership of data. Should the data about e.g.\nmy shopping and travel behavior belong to me or to the search engine or ride sharing company\nthat I use? Might consumers have a strong collective interest in ensuring that these data (suitably\nblinded, of course) are in the public domain, so that many companies can use them in the pursuit\nof innovation?\nOn the other, the advent of deep learning has significant implications for the patent\nsystem.  Though there has so far been relatively little patenting of deep learning innovations,\nhistorical episodes such as the discovery and attempted wholesale patenting of express sequence\ntags and other kinds of genetic data suggests that breakthroughs in research tools—often\ncombined with a lack of capacity at patent offices and conflicting court decisions—can result in\nlong periods of uncertainty that has hampered the issuing of new patents, and this in turn has led\nto lower research productivity and less competition.  Deep learning also presents difficult\nquestions of legal doctrine for patent systems that have been built around the idea of creative\nauthors and inventors.  For example, “inventorship” has a specific meaning in patent law, with\nvery important implications for ownership and control of the claimed invention.  Can an AI\nsystem be an inventor in the sense envisaged by the drafters of the US Constitution?  Similarly,\nstandards for determining the size of the inventive step required to obtain a patent are driven by a\ndetermination of whether the claimed invention would or would not be obvious to a “person\nhaving ordinary skill in the art.”  Who this “person” might be, and what constitutes “ordinary\n***END OF PAGE 27***","image":[],"pageNum":27},{"SlideNum":28,"PageNum":28,"Title":"skill in an age of deep learning systems trained on proprietary data are questions well beyond","Paragraph":"***START OF PAGE 28***\nskill” in an age of deep learning systems trained on proprietary data, are questions well beyond\nthe scope of this essay.\nIn addition to these traditional innovation policy questions, the prospect for deep learning\nraises a wide variety of other issues, including issues relating to privacy, the potential for bias\n(deep learning has been found to reinforce stereotypes already present in society), and consumer\nprotection (related to areas such as search, advertising, and consumer targeting and monitoring).\nThe key is that, to the extent that deep learning is general-purpose, the issues that arise across\neach of these domains (and more) will play out across a wide variety of sectors and contexts and\nat a global rather than local level.  Little analysis has been conducted that can help design\ninstitutions that will be responsive at the level of application sectors that also internalize the\npotential issues that may arise with the fact that deep learning is likely to be a GPT.\nFinally, the broad applicability of deep learning (and possibly robotics) across many\nsectors is likely to engender a race within each sector to establish a proprietary advantage that\nleverages these new approaches.  As such, the arrival of deep learning raises issues for\ncompetition policy.  In each application sector, there is the possibility that firms that are able to\nestablish an advantage at an early stage, and in doing so position themselves to be able to\ngenerate more data (about their technology, about customer behavior, about their organizational\nprocesses) will be able to erect a deep-learning-driven barrier to entry that will ensure market\ndominance over at least the medium term.  This suggests that rules ensuring data accessibility are\nnot only a matter of research productivity or aggregation, but also speak to the potential to guard\nagainst lock-in and anticompetitive conduct.  At the present moment there seem to be a large\nnumber of individual companies attempting to take advantage of AI across a wide variety of\ndomains (e.g., there are probably more than 20 firms engaging in significant levels of research in\nautonomous vehicles, and no firm has yet to show a decisive advantage), but this high level of\nactivity likely reflects an expectation for the prospects for significant market power in the future.\nEnsuring that deep learning does not enhance monopolization and increase barriers to entry\nacross a range of sectors will be a key topic going forward.\n***END OF PAGE 28***","title":"skill in an age of deep learning systems trained on proprietary data are questions well beyond","slideNum":28,"paragraph":"***START OF PAGE 28***\nskill” in an age of deep learning systems trained on proprietary data, are questions well beyond\nthe scope of this essay.\nIn addition to these traditional innovation policy questions, the prospect for deep learning\nraises a wide variety of other issues, including issues relating to privacy, the potential for bias\n(deep learning has been found to reinforce stereotypes already present in society), and consumer\nprotection (related to areas such as search, advertising, and consumer targeting and monitoring).\nThe key is that, to the extent that deep learning is general-purpose, the issues that arise across\neach of these domains (and more) will play out across a wide variety of sectors and contexts and\nat a global rather than local level.  Little analysis has been conducted that can help design\ninstitutions that will be responsive at the level of application sectors that also internalize the\npotential issues that may arise with the fact that deep learning is likely to be a GPT.\nFinally, the broad applicability of deep learning (and possibly robotics) across many\nsectors is likely to engender a race within each sector to establish a proprietary advantage that\nleverages these new approaches.  As such, the arrival of deep learning raises issues for\ncompetition policy.  In each application sector, there is the possibility that firms that are able to\nestablish an advantage at an early stage, and in doing so position themselves to be able to\ngenerate more data (about their technology, about customer behavior, about their organizational\nprocesses) will be able to erect a deep-learning-driven barrier to entry that will ensure market\ndominance over at least the medium term.  This suggests that rules ensuring data accessibility are\nnot only a matter of research productivity or aggregation, but also speak to the potential to guard\nagainst lock-in and anticompetitive conduct.  At the present moment there seem to be a large\nnumber of individual companies attempting to take advantage of AI across a wide variety of\ndomains (e.g., there are probably more than 20 firms engaging in significant levels of research in\nautonomous vehicles, and no firm has yet to show a decisive advantage), but this high level of\nactivity likely reflects an expectation for the prospects for significant market power in the future.\nEnsuring that deep learning does not enhance monopolization and increase barriers to entry\nacross a range of sectors will be a key topic going forward.\n***END OF PAGE 28***","image":[],"pageNum":28},{"SlideNum":29,"PageNum":29,"Title":"VIII Concluding Thoughts","Paragraph":"***START OF PAGE 29***\nVIII. Concluding Thoughts\nThe purpose of this exploratory essay has not been to provide a systematic account or\nprediction of the likely impact of AI on innovation, nor clear guidance for policy or the\nmanagement of innovation.  Instead, our goal has been to raise a specific possibility—that deep\nlearning represents a new general-purpose invention of a method of invention—and to draw out\nsome preliminary implications of that hypothesis for management, institutions, and policy.\nOur preliminary analysis highlights a few key ideas that have not been central to the\neconomics and policy discussion so far.  First, at least from the perspective of innovation, it is\nuseful to distinguish between the significant and important advances in fields such as robotics\nfrom the potential of a general-purpose method of invention based on application of multi-\nlayered neural networks to large amounts of digital data to be an “invention in the method of\ninvention”.  Both the existing qualitative evidence and our preliminary empirical analysis\ndocuments a striking shift since 2009 towards deep learning based application-oriented research\nthat is consistent with this possibility. Second, and relatedly, the prospect of a change in the\ninnovation process raises key issues for a range of policy and management areas, ranging from\nhow to evaluate this new type of science to the potential for prediction methods to induce new\nbarriers to entry across a wide range of industries.  Proactive analysis of the appropriate private\nand public policy responses towards these breakthroughs seems like an extremely promising area\nfor future research.\n***END OF PAGE 29***","title":"VIII Concluding Thoughts","slideNum":29,"paragraph":"***START OF PAGE 29***\nVIII. Concluding Thoughts\nThe purpose of this exploratory essay has not been to provide a systematic account or\nprediction of the likely impact of AI on innovation, nor clear guidance for policy or the\nmanagement of innovation.  Instead, our goal has been to raise a specific possibility—that deep\nlearning represents a new general-purpose invention of a method of invention—and to draw out\nsome preliminary implications of that hypothesis for management, institutions, and policy.\nOur preliminary analysis highlights a few key ideas that have not been central to the\neconomics and policy discussion so far.  First, at least from the perspective of innovation, it is\nuseful to distinguish between the significant and important advances in fields such as robotics\nfrom the potential of a general-purpose method of invention based on application of multi-\nlayered neural networks to large amounts of digital data to be an “invention in the method of\ninvention”.  Both the existing qualitative evidence and our preliminary empirical analysis\ndocuments a striking shift since 2009 towards deep learning based application-oriented research\nthat is consistent with this possibility. Second, and relatedly, the prospect of a change in the\ninnovation process raises key issues for a range of policy and management areas, ranging from\nhow to evaluate this new type of science to the potential for prediction methods to induce new\nbarriers to entry across a wide range of industries.  Proactive analysis of the appropriate private\nand public policy responses towards these breakthroughs seems like an extremely promising area\nfor future research.\n***END OF PAGE 29***","image":[],"pageNum":29},{"SlideNum":30,"PageNum":30,"Title":"REFERENCES","Paragraph":"***START OF PAGE 30***\nREFERENCES\nAghion, P. and P. Howitt (1992) “A Model of Growth Through Creative Destruction,” Econometrica, 60(2),\nBresnahan, T., E. Brynjolfsson, and L. Hitt (2002) “Information Technology, Workplace Organization, and\nthe Demand for Skilled Labor: Firm-Level Evidence,” The Quarterly Journal of Economics, 117(1),\nBresnahan, T. and S. Greenstein (1999) “Technological Competition and the Structure of the Computer\nIndustry,” Journal of Industrial Economics, 47(1), 1-40.\nBresnahan, T. and M. Trajtenberg (1995) “General Purpose Technologies ‘Engines of Growth’?” Journal\nof Econometrics, 65 (1995) 83-108.\nBrooks, R. (1990) “Elephants Don’t Play Chess,” Robotics and Autonomous Systems, 6, 3-15.\nBrooks, R. (1991) “Intelligence Without Representation,” Artificial Intelligence, 47, 139-159.\nBrynjolfsson, E. and K. McElheran (2017) “The Rapid Adoption of Data-Driven Decision-Making,”\nAmerican Economic Review, 106(5), 133-139\nGriliches, Z. (1957) “Hybrid Corn: An Exploration in the Economics of Technological Change,”\nEconometrica, 25(4), 501-522.\nHenderson, R. and K. Clark (1990) “Architectural Innovation: The Reconfiguration of Existing Product\nTechnologies and the Failure of Established Firms,” Administrative Science Quarterly, 35(1), 9-30.\nKrizhevsky, A., I. Sutskever, G. Hinton (2012) “ImageNet Classification with Deep Convolutional Neural\nNetworks,” Advances in Neural Information Processing, 25, MIT Press.\nLeung, M.K.K., A. Delong, B. Alipanahi, and B.J. Frey (2016) “Machine Learning in Genomic Medicine:\nA Review of Computational Problems and Data Sets,” Proceedings of the IEEE, 104(1): 176-197.\nMarco, A., A. Myers, S. Graham, P. D’Agostino, and K. Apple (2015) “The USPTO Patent Assignment\nDataset: Descriptions and Analysis,” USPTO Working Paper No. 2015-02, 1-53.\nMarco, A., M. Carley, S. Jackson and A. Myers (2015) “The USPTO Historical Patent Data Files,” USPTO\nWorking Paper No. 2015-01, 1-57.\nMinsky, M. (1961) “Steps Toward Artificial Intelligence,” Proceedings of the IRE, 8-30.\nMokyr, J (2002) Gifts of Athena, Princeton University Press.\nNilsson, N. (2010), The Quest for Artificial Intelligence: A History of Ideas and Achievements, Cambridge\nUniversity Press.\nRomer, P. (1990) “Endogenous Technological Change,” Journal of Political Economy, 98(5), S71-S102.\nRosenberg, N. and M. Trajtenberg (2004) “A General Purpose Technology at Work: The Corliss Steam\nEngine in the Late-Nineteenth-Century United States,” Journal of Economic History, 61(1), 61-99.\n***END OF PAGE 30***","title":"REFERENCES","slideNum":30,"paragraph":"***START OF PAGE 30***\nREFERENCES\nAghion, P. and P. Howitt (1992) “A Model of Growth Through Creative Destruction,” Econometrica, 60(2),\nBresnahan, T., E. Brynjolfsson, and L. Hitt (2002) “Information Technology, Workplace Organization, and\nthe Demand for Skilled Labor: Firm-Level Evidence,” The Quarterly Journal of Economics, 117(1),\nBresnahan, T. and S. Greenstein (1999) “Technological Competition and the Structure of the Computer\nIndustry,” Journal of Industrial Economics, 47(1), 1-40.\nBresnahan, T. and M. Trajtenberg (1995) “General Purpose Technologies ‘Engines of Growth’?” Journal\nof Econometrics, 65 (1995) 83-108.\nBrooks, R. (1990) “Elephants Don’t Play Chess,” Robotics and Autonomous Systems, 6, 3-15.\nBrooks, R. (1991) “Intelligence Without Representation,” Artificial Intelligence, 47, 139-159.\nBrynjolfsson, E. and K. McElheran (2017) “The Rapid Adoption of Data-Driven Decision-Making,”\nAmerican Economic Review, 106(5), 133-139\nGriliches, Z. (1957) “Hybrid Corn: An Exploration in the Economics of Technological Change,”\nEconometrica, 25(4), 501-522.\nHenderson, R. and K. Clark (1990) “Architectural Innovation: The Reconfiguration of Existing Product\nTechnologies and the Failure of Established Firms,” Administrative Science Quarterly, 35(1), 9-30.\nKrizhevsky, A., I. Sutskever, G. Hinton (2012) “ImageNet Classification with Deep Convolutional Neural\nNetworks,” Advances in Neural Information Processing, 25, MIT Press.\nLeung, M.K.K., A. Delong, B. Alipanahi, and B.J. Frey (2016) “Machine Learning in Genomic Medicine:\nA Review of Computational Problems and Data Sets,” Proceedings of the IEEE, 104(1): 176-197.\nMarco, A., A. Myers, S. Graham, P. D’Agostino, and K. Apple (2015) “The USPTO Patent Assignment\nDataset: Descriptions and Analysis,” USPTO Working Paper No. 2015-02, 1-53.\nMarco, A., M. Carley, S. Jackson and A. Myers (2015) “The USPTO Historical Patent Data Files,” USPTO\nWorking Paper No. 2015-01, 1-57.\nMinsky, M. (1961) “Steps Toward Artificial Intelligence,” Proceedings of the IRE, 8-30.\nMokyr, J (2002) Gifts of Athena, Princeton University Press.\nNilsson, N. (2010), The Quest for Artificial Intelligence: A History of Ideas and Achievements, Cambridge\nUniversity Press.\nRomer, P. (1990) “Endogenous Technological Change,” Journal of Political Economy, 98(5), S71-S102.\nRosenberg, N. and M. Trajtenberg (2004) “A General Purpose Technology at Work: The Corliss Steam\nEngine in the Late-Nineteenth-Century United States,” Journal of Economic History, 61(1), 61-99.\n***END OF PAGE 30***","image":[],"pageNum":30},{"SlideNum":31,"PageNum":31,"Title":"Rumelhart D G Hinton and R Williams  Learning Internal Representations by Error","Paragraph":"***START OF PAGE 31***\nRumelhart, D., G. Hinton, and R. Williams (1986) “Learning Internal Representations by Error\nPropagation,” in J. McClelland and D. Rumelhart (editors), Parallel Distributed Processing:\nExplorations in the Microstructure of Cognition, Volume 2: Psychological and Biological Models, MIT\nPress, 7-57.\nScotchmer, S. (1991) “Standing on the Shoulders of Giants: Cumulative Research and the Patent Law,”\nJournal of Economic Perspectives, 5(1), 29-41.\nTuring, A. (1950) “Computing Machinery and Intelligence,” Mind, 59, 433-460.\nWallach, I. Dzamba, M. and Heifels, A. “AtomNet: A Deep Convolutional Neural Network for Bioactivity\nPrediction in Structure-based Drug Discovery.”  arXiv:1510.02855 [cs.LG]\nWilliams, H. .(2013) “Intellectual Property Rights and Innovation: Evidence from the Human Genome,”,\nJournal of Political Economy, 121(1): 1-27\n***END OF PAGE 31***","title":"Rumelhart D G Hinton and R Williams  Learning Internal Representations by Error","slideNum":31,"paragraph":"***START OF PAGE 31***\nRumelhart, D., G. Hinton, and R. Williams (1986) “Learning Internal Representations by Error\nPropagation,” in J. McClelland and D. Rumelhart (editors), Parallel Distributed Processing:\nExplorations in the Microstructure of Cognition, Volume 2: Psychological and Biological Models, MIT\nPress, 7-57.\nScotchmer, S. (1991) “Standing on the Shoulders of Giants: Cumulative Research and the Patent Law,”\nJournal of Economic Perspectives, 5(1), 29-41.\nTuring, A. (1950) “Computing Machinery and Intelligence,” Mind, 59, 433-460.\nWallach, I. Dzamba, M. and Heifels, A. “AtomNet: A Deep Convolutional Neural Network for Bioactivity\nPrediction in Structure-based Drug Discovery.”  arXiv:1510.02855 [cs.LG]\nWilliams, H. .(2013) “Intellectual Property Rights and Innovation: Evidence from the Human Genome,”,\nJournal of Political Economy, 121(1): 1-27\n***END OF PAGE 31***","image":[],"pageNum":31},{"SlideNum":32,"PageNum":32,"Title":"Table A  Publication Data Summary Statistics","Paragraph":"***START OF PAGE 32***\nTable 1A:  Publication Data Summary Statistics\nMean Std. Dev. Min Max\nPublication Year 2007 6.15 1990 2015\nSymbolic Systems .12 .33 0 1\nLearning Systems .61 .48 0 1\nRobotics .21 .41 0 1\nArtificial Intelligence .06 .23 0 1\nComputer Science .44 .50 0 1\nOther Applications .56 .50 0 1\nUS Domestic .25 .43 0 1\nInternational .75 .43 0 1\nObservations 95840\nTable 1B: Patent Data Summary Statistics\nMean Std. Dev. Min Max\nApplication Year 2003 6.68 1982 2014\nSymbolic Systems .29 .45 0 1\nLearning Systems .28 .45 0 1\nRobotics .41 .49 0 1\nArtificial Intelligence .04 .19 0 1\nComputer Science .77 .42 0 1\nOther Applications .23 .42 0 1\nUS Domestic Firms .59 .49 0 1\nInternational Firms .41 .49 0 1\nOrg Type Academic .07 .26 0 1\nOrg Type Private .91 .29 0 1\nObservations 13615\n***END OF PAGE 32***","title":"Table A  Publication Data Summary Statistics","slideNum":32,"paragraph":"***START OF PAGE 32***\nTable 1A:  Publication Data Summary Statistics\nMean Std. Dev. Min Max\nPublication Year 2007 6.15 1990 2015\nSymbolic Systems .12 .33 0 1\nLearning Systems .61 .48 0 1\nRobotics .21 .41 0 1\nArtificial Intelligence .06 .23 0 1\nComputer Science .44 .50 0 1\nOther Applications .56 .50 0 1\nUS Domestic .25 .43 0 1\nInternational .75 .43 0 1\nObservations 95840\nTable 1B: Patent Data Summary Statistics\nMean Std. Dev. Min Max\nApplication Year 2003 6.68 1982 2014\nSymbolic Systems .29 .45 0 1\nLearning Systems .28 .45 0 1\nRobotics .41 .49 0 1\nArtificial Intelligence .04 .19 0 1\nComputer Science .77 .42 0 1\nOther Applications .23 .42 0 1\nUS Domestic Firms .59 .49 0 1\nInternational Firms .41 .49 0 1\nOrg Type Academic .07 .26 0 1\nOrg Type Private .91 .29 0 1\nObservations 13615\n***END OF PAGE 32***","image":[],"pageNum":32},{"SlideNum":33,"PageNum":33,"Title":"Table A Distribution of Publications across Subjects","Paragraph":"***START OF PAGE 33***\nTable 2A: Distribution of Publications across Subjects\nMean Std. Dev.\nBiology .034 .18\nEconomics .028 .16\nPhysics .034 .18\nMedicine .032 .18\nChemistry .038 .19\nMathematics .042 .20\nMaterials Science .029 .17\nNeurology .038 .19\nEnergy .015 .12\nRadiology .015 .12\nTelecommunications .055 .23\nComputer Science .44 .50\nObservations 95840\nTable 2B: Distribution of Patents across Application Sectors\nMean Std. Dev.\nChemicals .007 .08\nCommunications .044 .20\nComputer Hardware and\nSoftware\nComputer Peripherals .004 .06\nData and Storage .008 .09\nBusiness software .007 .09\nAll Computer Science .773 .42\nMedical .020 .14\nElectronics .073 .26\nAutomotive .023 .15\nMechanical .075 .26\nOther .029 .16\nObservations 13615\n***END OF PAGE 33***","title":"Table A Distribution of Publications across Subjects","slideNum":33,"paragraph":"***START OF PAGE 33***\nTable 2A: Distribution of Publications across Subjects\nMean Std. Dev.\nBiology .034 .18\nEconomics .028 .16\nPhysics .034 .18\nMedicine .032 .18\nChemistry .038 .19\nMathematics .042 .20\nMaterials Science .029 .17\nNeurology .038 .19\nEnergy .015 .12\nRadiology .015 .12\nTelecommunications .055 .23\nComputer Science .44 .50\nObservations 95840\nTable 2B: Distribution of Patents across Application Sectors\nMean Std. Dev.\nChemicals .007 .08\nCommunications .044 .20\nComputer Hardware and\nSoftware\nComputer Peripherals .004 .06\nData and Storage .008 .09\nBusiness software .007 .09\nAll Computer Science .773 .42\nMedical .020 .14\nElectronics .073 .26\nAutomotive .023 .15\nMechanical .075 .26\nOther .029 .16\nObservations 13615\n***END OF PAGE 33***","image":[],"pageNum":33},{"SlideNum":34,"PageNum":35,"Title":"Table  HerfindahlHirschman Index for Application Sectors","Paragraph":"***START OF PAGE 35***\nTable 4: Herfindahl-Hirschman Index for Application Sectors\nApplication Н= ∑𝑷𝒂𝒕𝑺𝒉𝒂𝒓𝒆\nChemical Applications 153.09\nCommunications 140.87\nHardware and Software 86.99\nComputer Science Peripherals 296\nData and Storage 366.71\nComputer Science Business Models 222\nMedical Applications 290.51\nElectronic Applications 114.64\nAutomotive Applications 197.03\nMechanical Applications 77.51\nOther 129.20\n***END OF PAGE 35***","title":"Table  HerfindahlHirschman Index for Application Sectors","slideNum":34,"paragraph":"***START OF PAGE 35***\nTable 4: Herfindahl-Hirschman Index for Application Sectors\nApplication Н= ∑𝑷𝒂𝒕𝑺𝒉𝒂𝒓𝒆\nChemical Applications 153.09\nCommunications 140.87\nHardware and Software 86.99\nComputer Science Peripherals 296\nData and Storage 366.71\nComputer Science Business Models 222\nMedical Applications 290.51\nElectronic Applications 114.64\nAutomotive Applications 197.03\nMechanical Applications 77.51\nOther 129.20\n***END OF PAGE 35***","image":[],"pageNum":35}]